/**
 * Script de migration des donnÃ©es de Supabase vers Cloudflare D1
 * 
 * Ce script permet de migrer les donnÃ©es de Supabase vers Cloudflare D1
 * en utilisant l'accÃ¨s direct PostgreSQL et l'API Cloudflare D1.
 */

// Importation des dÃ©pendances
const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');
const { exec } = require('child_process');
const dotenv = require('dotenv');

// Chargement des variables d'environnement
dotenv.config({ path: path.resolve(__dirname, '../.env') });

// Configuration PostgreSQL
const DATABASE_URL = process.env.DATABASE_URL;

// Configuration Cloudflare
const D1_DATABASE_NAME = 'flodrama-db';

// Tables Ã  migrer
const TABLES = ['dramas', 'films', 'animes', 'bollywood', 'scraping_logs'];

// Mapping des colonnes pour chaque table (colonnes Ã  conserver pour D1)
// BasÃ© sur l'analyse du schÃ©ma PostgreSQL et du schÃ©ma D1
const COLUMN_MAPPINGS = {
  dramas: ['id', 'title', 'description', 'poster', 'backdrop', 'rating', 'year', 'created_at', 'updated_at'],
  films: ['id', 'title', 'description', 'poster', 'backdrop', 'rating', 'year', 'created_at', 'updated_at'],
  animes: ['id', 'title', 'description', 'poster', 'backdrop', 'rating', 'year', 'created_at', 'updated_at'],
  bollywood: ['id', 'title', 'description', 'poster', 'backdrop', 'rating', 'year', 'created_at', 'updated_at'],
  scraping_logs: ['id', 'source', 'content_type', 'status', 'items_count', 'errors_count', 'duration', 'success', 'details', 'created_at']
};

// Pool de connexion PostgreSQL (pour accÃ¨s direct)
const pool = new Pool({
  connectionString: DATABASE_URL,
  ssl: { rejectUnauthorized: false }
});

/**
 * Fonction principale
 */
async function main() {
  // VÃ©rifier si le mode distant est activÃ©
  const isRemote = process.argv.includes('--remote');
  const remoteFlag = isRemote ? '--remote' : '';
  
  console.log(`ğŸš€ DÃ©marrage de la migration Supabase vers Cloudflare D1 ${isRemote ? '(DISTANT)' : '(LOCAL)'}`);
  
  try {
    // Test de connexion Ã  PostgreSQL
    console.log('ğŸ“¡ Test de connexion Ã  PostgreSQL...');
    const client = await pool.connect();
    console.log('âœ… Connexion Ã  PostgreSQL Ã©tablie avec succÃ¨s');
    
    // Migration des donnÃ©es pour chaque table
    for (const table of TABLES) {
      console.log(`\nğŸ“‹ Migration de la table ${table}...`);
      
      // RÃ©cupÃ©ration des donnÃ©es depuis PostgreSQL avec seulement les colonnes nÃ©cessaires
      const columns = COLUMN_MAPPINGS[table].join(', ');
      console.log(`ğŸ“¥ RÃ©cupÃ©ration des donnÃ©es depuis PostgreSQL (colonnes: ${columns})...`);
      const result = await client.query(`SELECT ${columns} FROM ${table}`);
      const data = result.rows;
      console.log(`âœ… ${data.length} enregistrements rÃ©cupÃ©rÃ©s`);
      
      if (data.length === 0) {
        console.log(`âš ï¸ Aucune donnÃ©e Ã  migrer pour la table ${table}`);
        continue;
      }
      
      // CrÃ©ation du fichier SQL pour l'insertion des donnÃ©es
      console.log(`ğŸ“ CrÃ©ation du fichier SQL pour l'insertion des donnÃ©es...`);
      const sqlFile = path.resolve(__dirname, `${table}_data.sql`);
      
      // Vider la table avant d'insÃ©rer de nouvelles donnÃ©es
      let sqlContent = `DELETE FROM ${table};\n`;
      
      // GÃ©nÃ©ration des requÃªtes INSERT
      for (const row of data) {
        const columns = Object.keys(row).join(', ');
        const values = Object.values(row).map(value => {
          if (value === null) return 'NULL';
          if (typeof value === 'string') return `'${value.replace(/'/g, "''")}'`;
          if (typeof value === 'object' && value instanceof Date) return `'${value.toISOString()}'`;
          if (typeof value === 'object') return `'${JSON.stringify(value).replace(/'/g, "''")}'`;
          return value;
        }).join(', ');
        
        sqlContent += `INSERT INTO ${table} (${columns}) VALUES (${values});\n`;
      }
      
      fs.writeFileSync(sqlFile, sqlContent);
      console.log(`âœ… Fichier SQL crÃ©Ã© avec succÃ¨s : ${sqlFile}`);
      
      // ExÃ©cution du fichier SQL sur Cloudflare D1
      console.log(`ğŸ“¤ ExÃ©cution du fichier SQL sur Cloudflare D1 ${isRemote ? '(DISTANT)' : '(LOCAL)'}...`);
      const command = `npx wrangler d1 execute ${D1_DATABASE_NAME} --file=${sqlFile} ${remoteFlag}`;
      
      await new Promise((resolve, reject) => {
        exec(command, { cwd: __dirname }, (error, stdout, stderr) => {
          if (error) {
            console.error(`âŒ Erreur lors de l'exÃ©cution de la commande : ${error.message}`);
            console.error(`Stderr : ${stderr}`);
            reject(error);
            return;
          }
          
          console.log(`âœ… DonnÃ©es insÃ©rÃ©es avec succÃ¨s dans Cloudflare D1 ${isRemote ? '(DISTANT)' : '(LOCAL)'}`);
          console.log(stdout);
          resolve();
        });
      });
    }
    
    // LibÃ©ration de la connexion PostgreSQL
    client.release();
    
    console.log('\nğŸ‰ Migration terminÃ©e avec succÃ¨s !');
  } catch (error) {
    console.error(`âŒ Erreur lors de la migration: ${error}`);
    throw error;
  } finally {
    // Fermeture du pool de connexion
    await pool.end();
  }
}

// ExÃ©cution de la fonction principale
main().catch(error => {
  console.error(`âŒ Erreur fatale: ${error}`);
  process.exit(1);
});
