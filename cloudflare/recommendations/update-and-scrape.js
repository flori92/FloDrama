/**
 * Script d'int√©gration pour mettre √† jour le syst√®me de recommandation FloDrama
 * Ce script applique les mises √† jour dynamiques et lance un nouveau scraping cibl√©
 */

import { updateScraperService } from './src/services/scraper-service-update.js';
import { updateRecommendationService } from './src/services/recommendation-service-update.js';
import { getDatabase } from './src/services/database.js';
import { ScraperService } from './src/services/scraper-service.js';

// Configuration
const API_KEY = '507f4127285e65f9b4882ea54719cfcd';
const API_ENDPOINT = 'https://flodrama-recommendations-prod.florifavi.workers.dev/api/scrape';

/**
 * Fonction principale
 */
async function main() {
  console.log('üöÄ D√©marrage de la mise √† jour et du scraping cibl√©...');
  
  try {
    // 1. Appliquer les mises √† jour dynamiques
    console.log('üìù Application des mises √† jour dynamiques...');
    
    // Mettre √† jour le service de scraping
    const targetYears = updateScraperService();
    console.log(`‚úÖ Service de scraping mis √† jour pour cibler les ann√©es: ${targetYears.join(', ')}`);
    
    // Mettre √† jour le service de recommandation
    const { minYear, currentYear } = updateRecommendationService();
    console.log(`‚úÖ Service de recommandation mis √† jour pour cibler les ann√©es: ${minYear} √† ${currentYear}`);
    
    // 2. Lancer un nouveau scraping cibl√©
    console.log('üîç Lancement du scraping cibl√©...');
    
    // Liste des sources √† scraper
    const sources = [
      'kissasian',
      'dramacool',
      'viewasian',
      'voirdrama',
      'gogoanime',
      'nekosama',
      'voiranime',
      'vostfree',
      'streamingdivx',
      'filmapik',
      'bollyplay',
      'hindilinks4u'
    ];
    
    // Lancer le scraping pour chaque source
    for (const source of sources) {
      console.log(`üìå Scraping de la source: ${source}`);
      
      try {
        // Appeler l'API de scraping
        const response = await fetch(API_ENDPOINT, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'X-API-Key': API_KEY
          },
          body: JSON.stringify({
            source_id: source,
            target_years: targetYears // Transmettre les ann√©es cibles
          })
        });
        
        if (!response.ok) {
          throw new Error(`Erreur HTTP: ${response.status}`);
        }
        
        const result = await response.json();
        console.log(`‚úÖ Scraping de ${source} termin√©: ${result.data[source]?.count || 0} √©l√©ments`);
      } catch (error) {
        console.error(`‚ùå Erreur lors du scraping de ${source}:`, error);
      }
      
      // Attendre 5 secondes entre chaque source pour √©viter de surcharger l'API
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
    
    console.log('‚úÖ Mise √† jour et scraping termin√©s avec succ√®s!');
    
    // 3. V√©rifier l'√©tat de la base de donn√©es
    console.log('üìä V√©rification de l\'√©tat de la base de donn√©es...');
    
    // Dans un environnement local, nous ne pouvons pas acc√©der directement √† la base de donn√©es Cloudflare D1
    // Nous allons donc simplement afficher les informations de configuration
    
    console.log(`üìä Configuration du scraping cibl√© pour les ann√©es ${minYear} √† ${currentYear}`);
    
    // Nous n'avons pas besoin d'initialiser la base de donn√©es locale
    // car nous allons utiliser l'API Cloudflare pour le scraping
    
    // Simuler les statistiques pour l'affichage
    const totalContents = "N/A (acc√®s direct √† D1 non disponible en local)";
    const targetContents = "N/A (acc√®s direct √† D1 non disponible en local)";
    const recentPercentage = "N/A";
    
    console.log(`Nombre total de contenus: ${totalContents}`);
    console.log(`Nombre de contenus entre ${minYear} et ${currentYear}: ${targetContents}`);
    console.log(`Pourcentage de contenus r√©cents: ${recentPercentage}%`);
    
    console.log('‚úÖ V√©rification termin√©e!');
  } catch (error) {
    console.error('‚ùå Erreur lors de la mise √† jour et du scraping:', error);
    process.exit(1);
  }
}

// Ex√©cuter la fonction principale
main().catch(console.error);
