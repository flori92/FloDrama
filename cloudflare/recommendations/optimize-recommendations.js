/**
 * Script d'optimisation du syst√®me de recommandation FloDrama
 * Ce script met √† jour la base de donn√©es pour se concentrer sur les contenus r√©cents
 * et optimise les requ√™tes de recommandation.
 */

import { getDatabase } from './src/services/database.js';
import { ScraperService } from './src/services/scraper-service.js';

// Configuration
const YEARS_RANGE = 2; // Nombre d'ann√©es √† prendre en compte (ann√©e courante - YEARS_RANGE)

/**
 * Fonction principale
 */
async function main() {
  console.log('üöÄ D√©marrage de l\'optimisation du syst√®me de recommandation...');
  
  try {
    // R√©cup√©rer l'environnement depuis les arguments
    const env = process.argv[2] || 'production';
    console.log(`Environnement: ${env}`);
    
    // Charger la configuration Wrangler
    const wranglerConfig = await import('./wrangler.toml', { assert: { type: 'toml' } });
    
    // Cr√©er un environnement simul√© pour les tests locaux
    const mockEnv = {
      DB: {}, // Sera remplac√© par D1
      FLODRAMA_METADATA: {}, // Sera remplac√© par KV
      ENVIRONMENT: env
    };
    
    // Initialiser la base de donn√©es
    const db = getDatabase(mockEnv);
    
    // Calculer la plage d'ann√©es dynamique
    const currentYear = new Date().getFullYear();
    const minYear = currentYear - YEARS_RANGE;
    
    console.log(`üìÖ Plage d'ann√©es pour les recommandations: ${minYear} - ${currentYear}`);
    
    // 1. Mettre √† jour la base de donn√©es pour se concentrer sur les contenus r√©cents
    await optimizeDatabase(db, minYear, currentYear);
    
    // 2. Lancer un nouveau scraping cibl√©
    await scrapeRecentContent(db, mockEnv, minYear, currentYear);
    
    console.log('‚úÖ Optimisation termin√©e avec succ√®s!');
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'optimisation:', error);
    process.exit(1);
  }
}

/**
 * Optimise la base de donn√©es pour se concentrer sur les contenus r√©cents
 */
async function optimizeDatabase(db, minYear, currentYear) {
  console.log('üìä Optimisation de la base de donn√©es...');
  
  try {
    // 1. Compter le nombre total de contenus
    const { results: countResults } = await db
      .prepare('SELECT COUNT(*) as total FROM contents')
      .all();
    
    const totalContents = countResults[0].total;
    console.log(`Nombre total de contenus: ${totalContents}`);
    
    // 2. Compter le nombre de contenus dans la plage d'ann√©es cible
    const { results: targetCountResults } = await db
      .prepare('SELECT COUNT(*) as total FROM contents WHERE release_year BETWEEN ? AND ?')
      .bind(minYear, currentYear)
      .all();
    
    const targetContents = targetCountResults[0].total;
    console.log(`Nombre de contenus entre ${minYear} et ${currentYear}: ${targetContents}`);
    
    // 3. Calculer le pourcentage de contenus r√©cents
    const recentPercentage = (targetContents / totalContents * 100).toFixed(2);
    console.log(`Pourcentage de contenus r√©cents: ${recentPercentage}%`);
    
    // 4. Si moins de 50% des contenus sont r√©cents, supprimer les anciens contenus
    if (recentPercentage < 50) {
      console.log('Suppression des contenus anciens...');
      
      const { results: deleteResults } = await db
        .prepare('DELETE FROM contents WHERE release_year < ?')
        .bind(minYear)
        .run();
      
      console.log(`Contenus supprim√©s: ${deleteResults.count}`);
    }
    
    console.log('Optimisation de la base de donn√©es termin√©e.');
  } catch (error) {
    console.error('Erreur lors de l\'optimisation de la base de donn√©es:', error);
    throw error;
  }
}

/**
 * Lance un nouveau scraping cibl√© sur les contenus r√©cents
 */
async function scrapeRecentContent(db, env, minYear, currentYear) {
  console.log('üîç Lancement du scraping cibl√©...');
  
  try {
    // Initialiser le service de scraping
    const scraper = new ScraperService({
      db,
      kv: env.FLODRAMA_METADATA,
      concurrency: 2,
      maxRetries: 3,
      targetYears: [minYear, currentYear] // Ajouter la plage d'ann√©es cible
    });
    
    // Lancer le scraping pour toutes les sources
    await scraper.scrapeAllSources();
    
    console.log('Scraping cibl√© termin√©.');
  } catch (error) {
    console.error('Erreur lors du scraping cibl√©:', error);
    throw error;
  }
}

// Ex√©cuter la fonction principale
main().catch(console.error);
