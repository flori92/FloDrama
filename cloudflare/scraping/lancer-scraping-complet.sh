#!/bin/bash
# Script de lancement complet du scraping FloDrama
# Ce script lance le scraping, analyse les rÃ©sultats et surveille la santÃ© des sources

# Couleurs pour les messages
ROUGE='\033[0;31m'
VERT='\033[0;32m'
JAUNE='\033[0;33m'
BLEU='\033[0;34m'
NC='\033[0m' # No Color

# Dossier courant
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"

# Fonction pour afficher un message avec timestamp
log() {
  echo -e "${BLEU}[$(date +"%Y-%m-%d %H:%M:%S")]${NC} $1"
}

# Fonction pour afficher une section
section() {
  echo ""
  echo -e "${JAUNE}========== $1 ==========${NC}"
  echo ""
}

# VÃ©rifier si Node.js est installÃ©
if ! command -v node &> /dev/null; then
  echo -e "${ROUGE}âŒ Node.js n'est pas installÃ©. Veuillez l'installer pour continuer.${NC}"
  exit 1
fi

# CrÃ©er les dossiers nÃ©cessaires
mkdir -p "$DIR/output"
mkdir -p "$DIR/reports"
mkdir -p "$DIR/source-health"

# VÃ©rifier si le port 3000 est dÃ©jÃ  utilisÃ©
PORT=3000
if lsof -Pi :$PORT -sTCP:LISTEN -t >/dev/null ; then
  echo -e "${ROUGE}âŒ Le port $PORT est dÃ©jÃ  utilisÃ©. ArrÃªt du processus existant...${NC}"
  PID=$(lsof -Pi :$PORT -sTCP:LISTEN -t)
  kill -9 $PID 2>/dev/null || true
  sleep 2
  
  # VÃ©rifier Ã  nouveau
  if lsof -Pi :$PORT -sTCP:LISTEN -t >/dev/null ; then
    echo -e "${ROUGE}âŒ Impossible de libÃ©rer le port $PORT. Veuillez arrÃªter manuellement le processus.${NC}"
    exit 1
  else
    echo -e "${VERT}âœ… Port $PORT libÃ©rÃ© avec succÃ¨s.${NC}"
  fi
fi

# DÃ©marrer le serveur relay en arriÃ¨re-plan
section "DÃ‰MARRAGE DU SERVEUR RELAY"
log "ğŸš€ DÃ©marrage du serveur relay local..."

# Sauvegarder le PID dans un fichier pour pouvoir l'arrÃªter plus tard
node "$DIR/serveur-relay-local-v2.js" > "$DIR/relay-logs.txt" 2>&1 &
RELAY_PID=$!
echo $RELAY_PID > "$DIR/relay_pid.txt"
echo "running" > "$DIR/relay_status.txt"

log "âœ… Serveur relay dÃ©marrÃ© avec PID: $RELAY_PID"
log "ğŸ“ Logs disponibles dans: $DIR/relay-logs.txt"

# Attendre que le serveur soit prÃªt et vÃ©rifier qu'il fonctionne correctement
log "â³ Attente du dÃ©marrage complet du serveur relay..."
sleep 5

# VÃ©rifier que le serveur est bien en cours d'exÃ©cution
if ! ps -p $RELAY_PID > /dev/null; then
  echo -e "${ROUGE}âŒ Le serveur relay n'a pas dÃ©marrÃ© correctement. VÃ©rifiez les logs pour plus de dÃ©tails.${NC}"
  cat "$DIR/relay-logs.txt"
  exit 1
fi

# Lancer le scraping
section "LANCEMENT DU SCRAPING"
log "ğŸ” DÃ©marrage du scraping sur toutes les sources..."

node "$DIR/test-scraping-local.js"

log "âœ… Scraping terminÃ©"

# Analyser les rÃ©sultats
section "ANALYSE DES RÃ‰SULTATS"
log "ğŸ“Š Analyse des rÃ©sultats du scraping..."

node "$DIR/analyze-scraping-results.js"

# Surveiller la santÃ© des sources
section "SURVEILLANCE DE LA SANTÃ‰ DES SOURCES"
log "ğŸ¥ VÃ©rification de la santÃ© des sources..."

node "$DIR/monitor-sources-health.js"

# ArrÃªter le serveur relay
section "ARRÃŠT DU SERVEUR RELAY"
log "ğŸ›‘ ArrÃªt du serveur relay local..."

if [ -f "$DIR/relay_pid.txt" ]; then
  RELAY_PID=$(cat "$DIR/relay_pid.txt")
  if ps -p $RELAY_PID > /dev/null; then
    kill $RELAY_PID || true
    sleep 1
    # VÃ©rifier si le processus est toujours en cours d'exÃ©cution
    if ps -p $RELAY_PID > /dev/null; then
      log "âš ï¸ Le processus ne s'est pas arrÃªtÃ© normalement, utilisation de kill -9"
      kill -9 $RELAY_PID || true
    fi
  else
    log "âš ï¸ Le processus $RELAY_PID n'est plus en cours d'exÃ©cution"
  fi
  rm "$DIR/relay_pid.txt"
  echo "stopped" > "$DIR/relay_status.txt"
  log "âœ… Serveur relay arrÃªtÃ©"
else
  log "âš ï¸ Fichier PID non trouvÃ©, recherche des processus node en cours..."
  # Rechercher les processus node qui pourraient Ãªtre le serveur relay
  NODE_PIDS=$(ps aux | grep "[n]ode.*serveur-relay" | awk '{print $2}')
  if [ -n "$NODE_PIDS" ]; then
    log "ğŸ” Processus serveur relay trouvÃ©s: $NODE_PIDS"
    for PID in $NODE_PIDS; do
      kill $PID || true
    done
    log "âœ… Processus arrÃªtÃ©s"
  else
    log "âœ… Aucun processus serveur relay en cours d'exÃ©cution"
  fi
fi

# RÃ©sumÃ© final
section "RÃ‰SUMÃ‰"
log "âœ… Processus de scraping complet terminÃ©"
log "ğŸ“ RÃ©sultats disponibles dans:"
log "   - DonnÃ©es: $DIR/output/"
log "   - Rapports: $DIR/reports/"
log "   - SantÃ© des sources: $DIR/source-health/"

echo ""
log "${VERT}Merci d'avoir utilisÃ© le systÃ¨me de scraping FloDrama !${NC}"
echo ""
