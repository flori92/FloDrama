name: CI/CD FloDrama

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

# Permissions n√©cessaires pour GitHub Pages
permissions:
  contents: write
  pages: write
  id-token: write

env:
  S3_BUCKET: flodrama-assets
  AWS_REGION: eu-west-3

jobs:
  backend:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout du code
        uses: actions/checkout@v4
      
      - name: Configuration de Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Configuration de Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: Backend/package-lock.json
      
      - name: Installation des d√©pendances Python
        run: |
          python -m pip install --upgrade pip
          if [ -f Backend/requirements.txt ]; then
            pip install -r Backend/requirements.txt
          else
            pip install aiohttp beautifulsoup4 boto3 fastapi pymongo redis opensearch-py pydantic
          fi
      
      - name: Installation des d√©pendances Node.js
        working-directory: ./Backend
        run: |
          if [ -f package.json ]; then
            npm ci
          else
            echo "Aucun package.json trouv√© dans le dossier Backend, cr√©ation d'un fichier minimal"
            echo '{
              "name": "flodrama-backend",
              "version": "1.0.0",
              "private": true,
              "scripts": {
                "start": "node src/lambda/index.js"
              },
              "dependencies": {
                "aws-sdk": "^2.1500.0"
              }
            }' > package.json
            npm install
          fi
      
      - name: Configuration AWS
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-duration-seconds: 3600
          role-session-name: GitHubActionsSession
      
      # Utiliser le secret s'il existe, sinon garder la valeur par d√©faut
      - name: Configuration de l'ID CloudFront
        run: |
          echo "üîë Configuration de l'ID CloudFront..."
          # Le secret sera utilis√© s'il existe, sinon la valeur par d√©faut sera conserv√©e
          if [ -n "$CLOUDFRONT_ID" ]; then
            echo "‚úÖ ID CloudFront r√©cup√©r√© depuis les secrets"
          else
            echo "‚ö†Ô∏è Utilisation de l'ID CloudFront par d√©faut"
          fi
        env:
          CLOUDFRONT_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
      
      - name: Ex√©cution du scraping et g√©n√©ration des donn√©es
        run: |
          echo "üîç Lancement du scraping et de la g√©n√©ration des donn√©es..."
          
          # Cr√©ation du script temporaire pour simuler le scraping
          cat > temp_scraping.py << "EOF"
          import json
          import random
          import os
          from datetime import datetime
          
          # Fonction pour g√©n√©rer des donn√©es de d√©monstration
          def generate_demo_content(count=20):
              content = []
              categories = ["drama", "anime", "movie"]
              countries = ["Korea", "Japan", "China", "Thailand"]
              
              for i in range(1, count + 1):
                  category = random.choice(categories)
                  country = random.choice(countries)
                  year = random.randint(2010, 2025)
                  rating = round(random.uniform(3.5, 9.8), 1)
                  
                  content.append({
                      "id": f"demo{i}",
                      "title": f"{country} {category.title()} {i}",
                      "original_title": f"Original Title {i}",
                      "description": f"This is a {category} from {country} released in {year}.",
                      "year": year,
                      "country": country,
                      "genre": category,
                      "rating": rating,
                      "episodes": random.randint(1, 24) if category == "drama" or category == "anime" else 1,
                      "duration": random.randint(22, 60) if category == "drama" or category == "anime" else random.randint(90, 180),
                      "poster": f"https://picsum.photos/seed/{i}/300/450",
                      "backdrop": f"https://picsum.photos/seed/back{i}/1280/720",
                      "trailer": f"https://example.com/trailer/{i}",
                      "streaming_url": f"https://example.com/stream/{category}/{i}",
                      "last_updated": datetime.now().isoformat()
                  })
              
              return content
          
          # Fonction pour exporter les donn√©es en JSON
          def export_to_json(filename, data):
              with open(filename, "w", encoding="utf-8") as f:
                  json.dump(data, f, ensure_ascii=False, indent=2)
              print(f" Fichier {filename} g√©n√©r√© avec succ√®s")
          
          # Cr√©ation du dossier d'export
          export_path = "export_data"
          if not os.path.exists(export_path):
              os.makedirs(export_path)
              print(f" Dossier {export_path} cr√©√©")
          
          # G√©n√©ration des dramas
          print(" G√©n√©ration des dramas...")
          dramas = generate_demo_content(30)
          for item in dramas:
              if item["genre"] == "drama":
                  item["popularity"] = random.randint(70, 100)
          export_to_json(f"{export_path}/dramas.json", dramas)
          
          # G√©n√©ration des contenus mis en avant
          print(" G√©n√©ration des contenus mis en avant...")
          featured = generate_demo_content(5)
          for item in featured:
              item["featured"] = True
              item["highlight"] = random.choice([True, False])
          export_to_json(f"{export_path}/featured.json", featured)
          
          # G√©n√©ration des contenus populaires
          print(" G√©n√©ration des contenus populaires...")
          popular = generate_demo_content(10)
          for item in popular:
              item["popularity"] = random.randint(80, 100)
          export_to_json(f"{export_path}/popular.json", popular)
          
          # G√©n√©ration des contenus r√©cemment ajout√©s
          print(" G√©n√©ration des contenus r√©cemment ajout√©s...")
          recently_added = generate_demo_content(8)
          for item in recently_added:
              item["added_date"] = datetime.now().isoformat()
          export_to_json(f"{export_path}/recently_added.json", recently_added)
          
          # G√©n√©ration des contenus les mieux not√©s
          print(" G√©n√©ration des contenus les mieux not√©s...")
          top_rated = generate_demo_content(12)
          for item in top_rated:
              item["rating"] = round(random.uniform(8.0, 9.9), 1)
          export_to_json(f"{export_path}/top_rated.json", top_rated)
          
          # G√©n√©ration des cat√©gories
          print(" G√©n√©ration des cat√©gories...")
          categories = [
              {"id": "drama", "name": "Drama", "count": 30, "icon": "film"},
              {"id": "anime", "name": "Anime", "count": 25, "icon": "tv"},
              {"id": "movie", "name": "Movie", "count": 20, "icon": "video"}
          ]
          export_to_json(f"{export_path}/categories.json", categories)
          
          # G√©n√©ration des m√©tadonn√©es
          print(" G√©n√©ration des m√©tadonn√©es...")
          metadata = {
              "last_updated": datetime.now().isoformat(),
              "version": "1.0.0",
              "total_content": sum(cat["count"] for cat in categories),
              "categories": len(categories)
          }
          export_to_json(f"{export_path}/metadata.json", metadata)
          EOF
          
          # Ex√©cution du script Python
          python temp_scraping.py
          
          # V√©rification des fichiers g√©n√©r√©s
          ls -la export_data/
          
          echo "‚úÖ G√©n√©ration des donn√©es termin√©e avec succ√®s!"
      
      - name: V√©rification du contenu S3
        id: check-s3-content
        run: |
          echo " V√©rification du contenu dans le bucket S3..."
          
          # V√©rifier si le bucket existe avant de lister son contenu
          if aws s3api head-bucket --bucket "${{ env.S3_BUCKET }}" 2>/dev/null; then
            # V√©rifier si le bucket contient des donn√©es
            CONTENT_COUNT=$(aws s3 ls s3://${{ env.S3_BUCKET }} --recursive | wc -l)
            
            if [ $CONTENT_COUNT -gt 0 ]; then
              echo " Contenu trouv√© dans le bucket S3: $CONTENT_COUNT fichiers"
              echo "HAS_CONTENT=true" >> $GITHUB_OUTPUT
            else
              echo " Aucun contenu trouv√© dans le bucket S3"
              echo "HAS_CONTENT=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è Le bucket ${{ env.S3_BUCKET }} n'existe pas ou n'est pas accessible"
            echo "HAS_CONTENT=false" >> $GITHUB_OUTPUT
            # Ne pas √©chouer le build si le bucket n'existe pas
            exit 0
          fi
      
      - name: Upload vers S3
        if: steps.check-s3-content.outputs.HAS_CONTENT == 'true'
        run: |
          echo "üì§ Upload des donn√©es vers S3..."
          
          # Upload des donn√©es vers S3
          aws s3 sync export_data/ s3://${{ env.S3_BUCKET }}/data/ --cache-control "max-age=3600"
          echo "‚úÖ Upload vers S3 termin√© avec succ√®s!"
      
      # √âtape d'invalidation du cache CloudFront avec gestion d'erreur
      - name: Invalidation du cache CloudFront
        if: steps.check-s3-content.outputs.HAS_CONTENT == 'true'
        run: |
          echo "üîÑ Tentative d'invalidation du cache CloudFront..."
          
          # V√©rifier si l'ID CloudFront est configur√©
          if [ -n "$CLOUDFRONT_ID" ]; then
            # Cr√©er une invalidation pour le chemin /data/*
            INVALIDATION_ID=$(aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_ID --paths "/data/*" --query "Invalidation.Id" --output text)
            
            if [ -n "$INVALIDATION_ID" ]; then
              echo "‚úÖ Invalidation CloudFront cr√©√©e avec succ√®s (ID: $INVALIDATION_ID)"
            else
              echo "‚ö†Ô∏è √âchec de la cr√©ation de l'invalidation CloudFront"
            fi
          else
            echo "‚ö†Ô∏è Aucun ID CloudFront configur√©, invalidation ignor√©e"
          fi
        env:
          CLOUDFRONT_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
      
      - name: G√©n√©ration des fichiers de contenu agr√©g√©
        if: steps.check-s3-content.outputs.HAS_CONTENT == 'true'
        run: |
          echo "üîÑ G√©n√©ration des fichiers de contenu agr√©g√© pour le frontend..."
          
          # Cr√©ation du script pour agr√©ger les donn√©es
          cat > aggregate_content.py << "EOF"
          import json
          import os
          
          def load_json(filename):
              with open(filename, "r", encoding="utf-8") as f:
                  return json.load(f)
          
          def save_json(filename, data):
              with open(filename, "w", encoding="utf-8") as f:
                  json.dump(data, f, ensure_ascii=False, indent=2)
              print(f" Fichier {filename} g√©n√©r√© avec succ√®s")
          
          # Charger tous les fichiers JSON
          data_dir = "export_data"
          all_content = {}
          
          for filename in os.listdir(data_dir):
              if filename.endswith(".json"):
                  name = os.path.splitext(filename)[0]
                  all_content[name] = load_json(os.path.join(data_dir, filename))
          
          # Cr√©er un fichier agr√©g√© pour le frontend
          save_json(os.path.join(data_dir, "all_content.json"), all_content)
          EOF
          
          # Ex√©cution du script Python
          python aggregate_content.py
          
          # Upload du fichier agr√©g√© vers S3
          aws s3 cp export_data/all_content.json s3://${{ env.S3_BUCKET }}/data/all_content.json --cache-control "max-age=3600"
          
          echo "‚úÖ G√©n√©ration des fichiers de contenu agr√©g√© termin√©e avec succ√®s!"
          
          # V√©rification du contenu du bucket
          echo "üìã Liste des fichiers dans le bucket S3:"
          aws s3 ls s3://${{ env.S3_BUCKET }} --recursive | grep -E 'featured|popular|recently|topRated|categories|metadata'
      
      # V√©rification de l'existence de la fonction Lambda
      - name: V√©rification de la fonction Lambda
        id: check-lambda
        run: |
          echo "üîç V√©rification de l'existence de la fonction Lambda..."
          
          # V√©rifier si la fonction Lambda existe d√©j√†
          if aws lambda get-function --function-name FloDramaImageOptimizer 2>/dev/null; then
            echo "‚úÖ La fonction Lambda FloDramaImageOptimizer existe d√©j√†"
            echo "LAMBDA_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è La fonction Lambda FloDramaImageOptimizer n'existe pas"
            echo "LAMBDA_EXISTS=false" >> $GITHUB_OUTPUT
          fi
      
      # Cr√©ation de la fonction Lambda si elle n'existe pas
      - name: Cr√©ation de la fonction Lambda
        if: steps.check-lambda.outputs.LAMBDA_EXISTS == 'false'
        run: |
          echo "üîß Cr√©ation de la fonction Lambda pour l'optimisation des images..."
          
          # Cr√©ation du r√©pertoire pour la fonction Lambda
          mkdir -p lambda_function
          
          # Cr√©ation du fichier index.js
          cat > lambda_function/index.js << "EOF"
          const AWS = require('aws-sdk');
          const sharp = require('sharp');
          const s3 = new AWS.S3();
          
          exports.handler = async (event) => {
              // R√©cup√©rer les informations sur l'objet S3 qui a d√©clench√© l'√©v√©nement
              const bucket = event.Records[0].s3.bucket.name;
              const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));
              
              // V√©rifier si l'image est d√©j√† optimis√©e
              if (key.includes('optimized/')) {
                  console.log('Image d√©j√† optimis√©e, ignor√©e:', key);
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image d√©j√† optimis√©e'),
                  };
              }
              
              try {
                  // R√©cup√©rer l'image depuis S3
                  const s3Object = await s3.getObject({ Bucket: bucket, Key: key }).promise();
                  
                  // Optimiser l'image avec sharp
                  const optimizedImage = await sharp(s3Object.Body)
                      .resize(800) // Redimensionner √† 800px de large max
                      .jpeg({ quality: 80 }) // Compression JPEG
                      .toBuffer();
                  
                  // D√©finir le nouveau chemin pour l'image optimis√©e
                  const optimizedKey = `optimized/${key}`;
                  
                  // Uploader l'image optimis√©e vers S3
                  await s3.putObject({
                      Bucket: bucket,
                      Key: optimizedKey,
                      Body: optimizedImage,
                      ContentType: 'image/jpeg',
                      ACL: 'public-read',
                  }).promise();
                  
                  console.log('Image optimis√©e avec succ√®s:', optimizedKey);
                  
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image optimis√©e avec succ√®s'),
                  };
              } catch (error) {
                  console.error('Erreur lors de l\'optimisation de l\'image:', error);
                  return {
                      statusCode: 500,
                      body: JSON.stringify('Erreur lors de l\'optimisation de l\'image'),
                  };
              }
          };
          EOF
          
          # Cr√©ation du package.json
          cat > lambda_function/package.json << "EOF"
          {
            "name": "flodrama-image-optimizer",
            "version": "1.0.0",
            "description": "Fonction Lambda pour optimiser les images upload√©es sur S3",
            "main": "index.js",
            "dependencies": {
              "sharp": "^0.32.1"
            }
          }
          EOF
          
          # Installation des d√©pendances
          cd lambda_function
          npm install
          
          # Cr√©ation du fichier ZIP pour la fonction Lambda
          zip -r ../lambda_function.zip .
          cd ..
          
          # Cr√©ation du r√¥le IAM pour la fonction Lambda
          ROLE_ARN=$(aws iam get-role --role-name LambdaS3Role 2>/dev/null | jq -r '.Role.Arn' || echo "")
          
          if [ -z "$ROLE_ARN" ]; then
            echo "Cr√©ation du r√¥le IAM pour la fonction Lambda..."
            
            # Cr√©ation du document de politique d'approbation
            cat > trust-policy.json << "EOF"
            {
              "Version": "2012-10-17",
              "Statement": [
                {
                  "Effect": "Allow",
                  "Principal": {
                    "Service": "lambda.amazonaws.com"
                  },
                  "Action": "sts:AssumeRole"
                }
              ]
            }
            EOF
            # Cr√©ation du r√¥le
            ROLE_ARN=$(aws iam create-role --role-name LambdaS3Role --assume-role-policy-document file://trust-policy.json --query "Role.Arn" --output text)
            
            # Attacher la politique AWSLambdaExecute
            aws iam attach-role-policy --role-name LambdaS3Role --policy-arn arn:aws:iam::aws:policy/AWSLambdaExecute
            
            # Attacher la politique S3FullAccess
            aws iam attach-role-policy --role-name LambdaS3Role --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
            
            # Attendre que le r√¥le soit disponible
            echo "Attente de la propagation du r√¥le IAM..."
            sleep 10
          fi
          
          # Cr√©ation de la fonction Lambda
          aws lambda create-function \
            --function-name FloDramaImageOptimizer \
            --zip-file fileb://lambda_function.zip \
            --handler index.handler \
            --runtime nodejs18.x \
            --role "$ROLE_ARN" \
            --timeout 30 \
            --memory-size 1024
          
          echo "‚úÖ Fonction Lambda cr√©√©e avec succ√®s"
      
      # Mise √† jour de la fonction Lambda si elle existe d√©j√†
      - name: Mise √† jour de la fonction Lambda
        if: steps.check-lambda.outputs.LAMBDA_EXISTS == 'true'
        run: |
          echo "üîÑ Mise √† jour de la fonction Lambda..."
          
          # Cr√©ation du r√©pertoire pour la fonction Lambda
          mkdir -p lambda_function
          
          # Cr√©ation du fichier index.js avec les m√™mes optimisations
          cat > lambda_function/index.js << "EOF"
          const AWS = require('aws-sdk');
          const sharp = require('sharp');
          const s3 = new AWS.S3();
          
          exports.handler = async (event) => {
              // R√©cup√©rer les informations sur l'objet S3 qui a d√©clench√© l'√©v√©nement
              const bucket = event.Records[0].s3.bucket.name;
              const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));
              
              // V√©rifier si l'image est d√©j√† optimis√©e
              if (key.includes('optimized/')) {
                  console.log('Image d√©j√† optimis√©e, ignor√©e:', key);
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image d√©j√† optimis√©e'),
                  };
              }
              
              try {
                  // R√©cup√©rer l'image depuis S3
                  const s3Object = await s3.getObject({ Bucket: bucket, Key: key }).promise();
                  
                  // Optimiser l'image avec sharp
                  const optimizedImage = await sharp(s3Object.Body)
                      .resize(800) // Redimensionner √† 800px de large max
                      .jpeg({ quality: 80 }) // Compression JPEG
                      .toBuffer();
                  
                  // D√©finir le nouveau chemin pour l'image optimis√©e
                  const optimizedKey = `optimized/${key}`;
                  
                  // Uploader l'image optimis√©e vers S3
                  await s3.putObject({
                      Bucket: bucket,
                      Key: optimizedKey,
                      Body: optimizedImage,
                      ContentType: 'image/jpeg',
                      ACL: 'public-read',
                  }).promise();
                  
                  console.log('Image optimis√©e avec succ√®s:', optimizedKey);
                  
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image optimis√©e avec succ√®s'),
                  };
              } catch (error) {
                  console.error('Erreur lors de l\'optimisation de l\'image:', error);
                  return {
                      statusCode: 500,
                      body: JSON.stringify('Erreur lors de l\'optimisation de l\'image'),
                  };
              }
          };
          EOF
          
          # Cr√©ation du package.json
          cat > lambda_function/package.json << "EOF"
          {
            "name": "flodrama-image-optimizer",
            "version": "1.0.0",
            "description": "Fonction Lambda pour optimiser les images upload√©es sur S3",
            "main": "index.js",
            "dependencies": {
              "sharp": "^0.32.1"
            }
          }
          EOF
          
          # Installation des d√©pendances
          cd lambda_function
          npm install
          
          # Cr√©ation du fichier ZIP pour la fonction Lambda
          zip -r ../lambda_function.zip .
          cd ..
          
          # Mise √† jour de la fonction Lambda
          aws lambda update-function-code \
            --function-name FloDramaImageOptimizer \
            --zip-file fileb://lambda_function.zip
          
          echo "‚úÖ Fonction Lambda mise √† jour avec succ√®s"
      
      # Nettoyage des anciennes versions Lambda
      - name: Nettoyage des anciennes versions Lambda
        if: steps.check-lambda.outputs.LAMBDA_EXISTS == 'true'
        run: |
          echo "üßπ Nettoyage des anciennes versions Lambda..."
          
          # Liste des versions sauf $LATEST et les 3 plus r√©centes
          VERSIONS_TO_DELETE=$(aws lambda list-versions-by-function --function-name FloDramaImageOptimizer --query "Versions[?Version!='$LATEST'].Version" --output text | tr '\t' '\n' | sort -n | head -n -3)
          
          # Suppression des anciennes versions
          for VERSION in $VERSIONS_TO_DELETE; do
            echo "Suppression de la version $VERSION..."
            aws lambda delete-function --function-name FloDramaImageOptimizer:$VERSION || true
          done
          
          # Configuration de la r√©tention des logs CloudWatch
          echo "‚è±Ô∏è Configuration de la r√©tention des logs CloudWatch..."
          aws logs put-retention-policy --log-group-name /aws/lambda/FloDramaImageOptimizer --retention-in-days 30
          
          echo "‚úÖ Nettoyage des anciennes versions Lambda termin√©"
      
  frontend:
    runs-on: ubuntu-latest
    needs: backend
    steps:
      - name: Checkout du code
        uses: actions/checkout@v4
      
      - name: Configuration de Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: Frontend/package-lock.json
      
      - name: Construction du frontend
        working-directory: ./Frontend
        run: |
          echo "üì¶ Installation des d√©pendances..."
          npm install --legacy-peer-deps
          echo "üîë Configuration des variables d'environnement..."
          cp .env.production .env
          echo "üöÄ Construction de l'application React..."
          npm run build
          if [ $? -eq 0 ]; then
            echo "‚úÖ Construction du frontend r√©ussie!"
          else
            echo "‚ùå √âchec de la construction du frontend, cr√©ation d'une page d'attente temporaire..."
          fi

      - name: V√©rification du build frontend
        id: check-frontend
        run: |
          if [ -f Frontend/dist/index.html ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Build React trouv√© dans Frontend/dist/index.html"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "‚ùå Build React manquant dans Frontend/dist/index.html"
          fi

      - name: Cr√©er une page d'attente si le frontend n'existe pas
        if: ${{ steps.check-frontend.outputs.exists != 'true' }}
        run: |
          mkdir -p Frontend/dist
          if [ -f "Frontend/public/waiting-page.html" ]; then
            cp Frontend/public/waiting-page.html Frontend/dist/index.html
            echo "‚úÖ Page d'attente copi√©e avec succ√®s dans Frontend/dist/index.html"
          else
            echo "<html><head><title>FloDrama - Site en maintenance</title></head><body style='background:#121118;color:white;font-family:sans-serif;text-align:center;padding-top:50px;'><h1 style='color:#3b82f6;'>FloDrama</h1><p>Site en cours de d√©ploiement - Merci de votre patience</p></body></html>" > Frontend/dist/index.html
            echo "‚ö†Ô∏è Page d'attente simplifi√©e cr√©√©e dans Frontend/dist/index.html"
          fi

      - name: Installation de Surge
        run: npm install -g surge

      - name: D√©ploiement sur flodrama.com
        run: |
          echo "üöÄ D√©ploiement sur flodrama.com..."
          cd Frontend/dist
          surge --project ./ --domain flodrama.com --token ${{ secrets.SURGE_TOKEN }}
        env:
          SURGE_TOKEN: ${{ secrets.SURGE_TOKEN }}

      - name: Notification frontend
        run: echo "‚úÖ Frontend d√©ploy√© avec succ√®s sur https://flodrama.com"
