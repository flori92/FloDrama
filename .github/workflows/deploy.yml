name: CI/CD FloDrama

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

# Permissions nécessaires pour GitHub Pages
permissions:
  contents: write
  pages: write
  id-token: write

env:
  S3_BUCKET: flodrama-assets
  AWS_REGION: eu-west-3

jobs:
  backend:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout du code
        uses: actions/checkout@v4
      
      - name: Configuration de Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Configuration de Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: Backend/package-lock.json
      
      - name: Installation des dépendances Python
        run: |
          python -m pip install --upgrade pip
          if [ -f Backend/requirements.txt ]; then
            pip install -r Backend/requirements.txt
          else
            pip install aiohttp beautifulsoup4 boto3 fastapi pymongo redis opensearch-py pydantic
          fi
      
      - name: Installation des dépendances Node.js
        working-directory: ./Backend
        run: |
          if [ -f package.json ]; then
            npm ci
          else
            echo "Aucun package.json trouvé dans le dossier Backend, création d'un fichier minimal"
            echo '{
              "name": "flodrama-backend",
              "version": "1.0.0",
              "private": true,
              "scripts": {
                "start": "node src/lambda/index.js"
              },
              "dependencies": {
                "aws-sdk": "^2.1500.0"
              }
            }' > package.json
            npm install
          fi
      
      - name: Configuration AWS
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          role-duration-seconds: 3600
          role-session-name: GitHubActionsSession
      
      # Utiliser le secret s'il existe, sinon garder la valeur par défaut
      - name: Configuration de l'ID CloudFront
        run: |
          echo "🔑 Configuration de l'ID CloudFront..."
          # Le secret sera utilisé s'il existe, sinon la valeur par défaut sera conservée
          if [ -n "$CLOUDFRONT_ID" ]; then
            echo "✅ ID CloudFront récupéré depuis les secrets"
          else
            echo "⚠️ Utilisation de l'ID CloudFront par défaut"
          fi
        env:
          CLOUDFRONT_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
      
      - name: Exécution du scraping et génération des données
        run: |
          echo "🔍 Lancement du scraping et de la génération des données..."
          
          # Création du script temporaire pour simuler le scraping
          cat > temp_scraping.py << "EOF"
          import json
          import random
          import os
          from datetime import datetime
          
          # Fonction pour générer des données de démonstration
          def generate_demo_content(count=20):
              content = []
              categories = ["drama", "anime", "movie"]
              countries = ["Korea", "Japan", "China", "Thailand"]
              
              for i in range(1, count + 1):
                  category = random.choice(categories)
                  country = random.choice(countries)
                  year = random.randint(2010, 2025)
                  rating = round(random.uniform(3.5, 9.8), 1)
                  
                  content.append({
                      "id": f"demo{i}",
                      "title": f"{country} {category.title()} {i}",
                      "original_title": f"Original Title {i}",
                      "description": f"This is a {category} from {country} released in {year}.",
                      "year": year,
                      "country": country,
                      "genre": category,
                      "rating": rating,
                      "episodes": random.randint(1, 24) if category == "drama" or category == "anime" else 1,
                      "duration": random.randint(22, 60) if category == "drama" or category == "anime" else random.randint(90, 180),
                      "poster": f"https://picsum.photos/seed/{i}/300/450",
                      "backdrop": f"https://picsum.photos/seed/back{i}/1280/720",
                      "trailer": f"https://example.com/trailer/{i}",
                      "streaming_url": f"https://example.com/stream/{category}/{i}",
                      "last_updated": datetime.now().isoformat()
                  })
              
              return content
          
          # Fonction pour exporter les données en JSON
          def export_to_json(filename, data):
              with open(filename, "w", encoding="utf-8") as f:
                  json.dump(data, f, ensure_ascii=False, indent=2)
              print(f" Fichier {filename} généré avec succès")
          
          # Création du dossier d'export
          export_path = "export_data"
          if not os.path.exists(export_path):
              os.makedirs(export_path)
              print(f" Dossier {export_path} créé")
          
          # Génération des dramas
          print(" Génération des dramas...")
          dramas = generate_demo_content(30)
          for item in dramas:
              if item["genre"] == "drama":
                  item["popularity"] = random.randint(70, 100)
          export_to_json(f"{export_path}/dramas.json", dramas)
          
          # Génération des contenus mis en avant
          print(" Génération des contenus mis en avant...")
          featured = generate_demo_content(5)
          for item in featured:
              item["featured"] = True
              item["highlight"] = random.choice([True, False])
          export_to_json(f"{export_path}/featured.json", featured)
          
          # Génération des contenus populaires
          print(" Génération des contenus populaires...")
          popular = generate_demo_content(10)
          for item in popular:
              item["popularity"] = random.randint(80, 100)
          export_to_json(f"{export_path}/popular.json", popular)
          
          # Génération des contenus récemment ajoutés
          print(" Génération des contenus récemment ajoutés...")
          recently_added = generate_demo_content(8)
          for item in recently_added:
              item["added_date"] = datetime.now().isoformat()
          export_to_json(f"{export_path}/recently_added.json", recently_added)
          
          # Génération des contenus les mieux notés
          print(" Génération des contenus les mieux notés...")
          top_rated = generate_demo_content(12)
          for item in top_rated:
              item["rating"] = round(random.uniform(8.0, 9.9), 1)
          export_to_json(f"{export_path}/top_rated.json", top_rated)
          
          # Génération des catégories
          print(" Génération des catégories...")
          categories = [
              {"id": "drama", "name": "Drama", "count": 30, "icon": "film"},
              {"id": "anime", "name": "Anime", "count": 25, "icon": "tv"},
              {"id": "movie", "name": "Movie", "count": 20, "icon": "video"}
          ]
          export_to_json(f"{export_path}/categories.json", categories)
          
          # Génération des métadonnées
          print(" Génération des métadonnées...")
          metadata = {
              "last_updated": datetime.now().isoformat(),
              "version": "1.0.0",
              "total_content": sum(cat["count"] for cat in categories),
              "categories": len(categories)
          }
          export_to_json(f"{export_path}/metadata.json", metadata)
          EOF
          
          # Exécution du script Python
          python temp_scraping.py
          
          # Vérification des fichiers générés
          ls -la export_data/
          
          echo "✅ Génération des données terminée avec succès!"
      
      - name: Vérification du contenu S3
        id: check-s3-content
        run: |
          echo " Vérification du contenu dans le bucket S3..."
          
          # Vérifier si le bucket existe avant de lister son contenu
          if aws s3api head-bucket --bucket "${{ env.S3_BUCKET }}" 2>/dev/null; then
            # Vérifier si le bucket contient des données
            CONTENT_COUNT=$(aws s3 ls s3://${{ env.S3_BUCKET }} --recursive | wc -l)
            
            if [ $CONTENT_COUNT -gt 0 ]; then
              echo " Contenu trouvé dans le bucket S3: $CONTENT_COUNT fichiers"
              echo "HAS_CONTENT=true" >> $GITHUB_OUTPUT
            else
              echo " Aucun contenu trouvé dans le bucket S3"
              echo "HAS_CONTENT=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "⚠️ Le bucket ${{ env.S3_BUCKET }} n'existe pas ou n'est pas accessible"
            echo "HAS_CONTENT=false" >> $GITHUB_OUTPUT
            # Ne pas échouer le build si le bucket n'existe pas
            exit 0
          fi
      
      - name: Upload vers S3
        if: steps.check-s3-content.outputs.HAS_CONTENT == 'true'
        run: |
          echo "📤 Upload des données vers S3..."
          
          # Upload des données vers S3
          aws s3 sync export_data/ s3://${{ env.S3_BUCKET }}/data/ --cache-control "max-age=3600"
          echo "✅ Upload vers S3 terminé avec succès!"
      
      # Étape d'invalidation du cache CloudFront avec gestion d'erreur
      - name: Invalidation du cache CloudFront
        if: steps.check-s3-content.outputs.HAS_CONTENT == 'true'
        run: |
          echo "🔄 Tentative d'invalidation du cache CloudFront..."
          
          # Vérifier si l'ID CloudFront est configuré
          if [ -n "$CLOUDFRONT_ID" ]; then
            # Créer une invalidation pour le chemin /data/*
            INVALIDATION_ID=$(aws cloudfront create-invalidation --distribution-id $CLOUDFRONT_ID --paths "/data/*" --query "Invalidation.Id" --output text)
            
            if [ -n "$INVALIDATION_ID" ]; then
              echo "✅ Invalidation CloudFront créée avec succès (ID: $INVALIDATION_ID)"
            else
              echo "⚠️ Échec de la création de l'invalidation CloudFront"
            fi
          else
            echo "⚠️ Aucun ID CloudFront configuré, invalidation ignorée"
          fi
        env:
          CLOUDFRONT_ID: ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }}
      
      - name: Génération des fichiers de contenu agrégé
        if: steps.check-s3-content.outputs.HAS_CONTENT == 'true'
        run: |
          echo "🔄 Génération des fichiers de contenu agrégé pour le frontend..."
          
          # Création du script pour agréger les données
          cat > aggregate_content.py << "EOF"
          import json
          import os
          
          def load_json(filename):
              with open(filename, "r", encoding="utf-8") as f:
                  return json.load(f)
          
          def save_json(filename, data):
              with open(filename, "w", encoding="utf-8") as f:
                  json.dump(data, f, ensure_ascii=False, indent=2)
              print(f" Fichier {filename} généré avec succès")
          
          # Charger tous les fichiers JSON
          data_dir = "export_data"
          all_content = {}
          
          for filename in os.listdir(data_dir):
              if filename.endswith(".json"):
                  name = os.path.splitext(filename)[0]
                  all_content[name] = load_json(os.path.join(data_dir, filename))
          
          # Créer un fichier agrégé pour le frontend
          save_json(os.path.join(data_dir, "all_content.json"), all_content)
          EOF
          
          # Exécution du script Python
          python aggregate_content.py
          
          # Upload du fichier agrégé vers S3
          aws s3 cp export_data/all_content.json s3://${{ env.S3_BUCKET }}/data/all_content.json --cache-control "max-age=3600"
          
          echo "✅ Génération des fichiers de contenu agrégé terminée avec succès!"
          
          # Vérification du contenu du bucket
          echo "📋 Liste des fichiers dans le bucket S3:"
          aws s3 ls s3://${{ env.S3_BUCKET }} --recursive | grep -E 'featured|popular|recently|topRated|categories|metadata'
      
      # Vérification de l'existence de la fonction Lambda
      - name: Vérification de la fonction Lambda
        id: check-lambda
        run: |
          echo "🔍 Vérification de l'existence de la fonction Lambda..."
          
          # Vérifier si la fonction Lambda existe déjà
          if aws lambda get-function --function-name FloDramaImageOptimizer 2>/dev/null; then
            echo "✅ La fonction Lambda FloDramaImageOptimizer existe déjà"
            echo "LAMBDA_EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ La fonction Lambda FloDramaImageOptimizer n'existe pas"
            echo "LAMBDA_EXISTS=false" >> $GITHUB_OUTPUT
          fi
      
      # Création de la fonction Lambda si elle n'existe pas
      - name: Création de la fonction Lambda
        if: steps.check-lambda.outputs.LAMBDA_EXISTS == 'false'
        run: |
          echo "🔧 Création de la fonction Lambda pour l'optimisation des images..."
          
          # Création du répertoire pour la fonction Lambda
          mkdir -p lambda_function
          
          # Création du fichier index.js
          cat > lambda_function/index.js << "EOF"
          const AWS = require('aws-sdk');
          const sharp = require('sharp');
          const s3 = new AWS.S3();
          
          exports.handler = async (event) => {
              // Récupérer les informations sur l'objet S3 qui a déclenché l'événement
              const bucket = event.Records[0].s3.bucket.name;
              const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));
              
              // Vérifier si l'image est déjà optimisée
              if (key.includes('optimized/')) {
                  console.log('Image déjà optimisée, ignorée:', key);
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image déjà optimisée'),
                  };
              }
              
              try {
                  // Récupérer l'image depuis S3
                  const s3Object = await s3.getObject({ Bucket: bucket, Key: key }).promise();
                  
                  // Optimiser l'image avec sharp
                  const optimizedImage = await sharp(s3Object.Body)
                      .resize(800) // Redimensionner à 800px de large max
                      .jpeg({ quality: 80 }) // Compression JPEG
                      .toBuffer();
                  
                  // Définir le nouveau chemin pour l'image optimisée
                  const optimizedKey = `optimized/${key}`;
                  
                  // Uploader l'image optimisée vers S3
                  await s3.putObject({
                      Bucket: bucket,
                      Key: optimizedKey,
                      Body: optimizedImage,
                      ContentType: 'image/jpeg',
                      ACL: 'public-read',
                  }).promise();
                  
                  console.log('Image optimisée avec succès:', optimizedKey);
                  
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image optimisée avec succès'),
                  };
              } catch (error) {
                  console.error('Erreur lors de l\'optimisation de l\'image:', error);
                  return {
                      statusCode: 500,
                      body: JSON.stringify('Erreur lors de l\'optimisation de l\'image'),
                  };
              }
          };
          EOF
          
          # Création du package.json
          cat > lambda_function/package.json << "EOF"
          {
            "name": "flodrama-image-optimizer",
            "version": "1.0.0",
            "description": "Fonction Lambda pour optimiser les images uploadées sur S3",
            "main": "index.js",
            "dependencies": {
              "sharp": "^0.32.1"
            }
          }
          EOF
          
          # Installation des dépendances
          cd lambda_function
          npm install
          
          # Création du fichier ZIP pour la fonction Lambda
          zip -r ../lambda_function.zip .
          cd ..
          
          # Création du rôle IAM pour la fonction Lambda
          ROLE_ARN=$(aws iam get-role --role-name LambdaS3Role 2>/dev/null | jq -r '.Role.Arn' || echo "")
          
          if [ -z "$ROLE_ARN" ]; then
            echo "Création du rôle IAM pour la fonction Lambda..."
            
            # Création du document de politique d'approbation
            cat > trust-policy.json << "EOF"
            {
              "Version": "2012-10-17",
              "Statement": [
                {
                  "Effect": "Allow",
                  "Principal": {
                    "Service": "lambda.amazonaws.com"
                  },
                  "Action": "sts:AssumeRole"
                }
              ]
            }
            EOF
            # Création du rôle
            ROLE_ARN=$(aws iam create-role --role-name LambdaS3Role --assume-role-policy-document file://trust-policy.json --query "Role.Arn" --output text)
            
            # Attacher la politique AWSLambdaExecute
            aws iam attach-role-policy --role-name LambdaS3Role --policy-arn arn:aws:iam::aws:policy/AWSLambdaExecute
            
            # Attacher la politique S3FullAccess
            aws iam attach-role-policy --role-name LambdaS3Role --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess
            
            # Attendre que le rôle soit disponible
            echo "Attente de la propagation du rôle IAM..."
            sleep 10
          fi
          
          # Création de la fonction Lambda
          aws lambda create-function \
            --function-name FloDramaImageOptimizer \
            --zip-file fileb://lambda_function.zip \
            --handler index.handler \
            --runtime nodejs18.x \
            --role "$ROLE_ARN" \
            --timeout 30 \
            --memory-size 1024
          
          echo "✅ Fonction Lambda créée avec succès"
      
      # Mise à jour de la fonction Lambda si elle existe déjà
      - name: Mise à jour de la fonction Lambda
        if: steps.check-lambda.outputs.LAMBDA_EXISTS == 'true'
        run: |
          echo "🔄 Mise à jour de la fonction Lambda..."
          
          # Création du répertoire pour la fonction Lambda
          mkdir -p lambda_function
          
          # Création du fichier index.js avec les mêmes optimisations
          cat > lambda_function/index.js << "EOF"
          const AWS = require('aws-sdk');
          const sharp = require('sharp');
          const s3 = new AWS.S3();
          
          exports.handler = async (event) => {
              // Récupérer les informations sur l'objet S3 qui a déclenché l'événement
              const bucket = event.Records[0].s3.bucket.name;
              const key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\+/g, ' '));
              
              // Vérifier si l'image est déjà optimisée
              if (key.includes('optimized/')) {
                  console.log('Image déjà optimisée, ignorée:', key);
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image déjà optimisée'),
                  };
              }
              
              try {
                  // Récupérer l'image depuis S3
                  const s3Object = await s3.getObject({ Bucket: bucket, Key: key }).promise();
                  
                  // Optimiser l'image avec sharp
                  const optimizedImage = await sharp(s3Object.Body)
                      .resize(800) // Redimensionner à 800px de large max
                      .jpeg({ quality: 80 }) // Compression JPEG
                      .toBuffer();
                  
                  // Définir le nouveau chemin pour l'image optimisée
                  const optimizedKey = `optimized/${key}`;
                  
                  // Uploader l'image optimisée vers S3
                  await s3.putObject({
                      Bucket: bucket,
                      Key: optimizedKey,
                      Body: optimizedImage,
                      ContentType: 'image/jpeg',
                      ACL: 'public-read',
                  }).promise();
                  
                  console.log('Image optimisée avec succès:', optimizedKey);
                  
                  return {
                      statusCode: 200,
                      body: JSON.stringify('Image optimisée avec succès'),
                  };
              } catch (error) {
                  console.error('Erreur lors de l\'optimisation de l\'image:', error);
                  return {
                      statusCode: 500,
                      body: JSON.stringify('Erreur lors de l\'optimisation de l\'image'),
                  };
              }
          };
          EOF
          
          # Création du package.json
          cat > lambda_function/package.json << "EOF"
          {
            "name": "flodrama-image-optimizer",
            "version": "1.0.0",
            "description": "Fonction Lambda pour optimiser les images uploadées sur S3",
            "main": "index.js",
            "dependencies": {
              "sharp": "^0.32.1"
            }
          }
          EOF
          
          # Installation des dépendances
          cd lambda_function
          npm install
          
          # Création du fichier ZIP pour la fonction Lambda
          zip -r ../lambda_function.zip .
          cd ..
          
          # Mise à jour de la fonction Lambda
          aws lambda update-function-code \
            --function-name FloDramaImageOptimizer \
            --zip-file fileb://lambda_function.zip
          
          echo "✅ Fonction Lambda mise à jour avec succès"
      
      # Nettoyage des anciennes versions Lambda
      - name: Nettoyage des anciennes versions Lambda
        if: steps.check-lambda.outputs.LAMBDA_EXISTS == 'true'
        run: |
          echo "🧹 Nettoyage des anciennes versions Lambda..."
          
          # Liste des versions sauf $LATEST et les 3 plus récentes
          VERSIONS_TO_DELETE=$(aws lambda list-versions-by-function --function-name FloDramaImageOptimizer --query "Versions[?Version!='$LATEST'].Version" --output text | tr '\t' '\n' | sort -n | head -n -3)
          
          # Suppression des anciennes versions
          for VERSION in $VERSIONS_TO_DELETE; do
            echo "Suppression de la version $VERSION..."
            aws lambda delete-function --function-name FloDramaImageOptimizer:$VERSION || true
          done
          
          # Configuration de la rétention des logs CloudWatch
          echo "⏱️ Configuration de la rétention des logs CloudWatch..."
          aws logs put-retention-policy --log-group-name /aws/lambda/FloDramaImageOptimizer --retention-in-days 30
          
          echo "✅ Nettoyage des anciennes versions Lambda terminé"
      
  frontend:
    runs-on: ubuntu-latest
    needs: backend
    steps:
      - name: Checkout du code
        uses: actions/checkout@v4
      
      - name: Configuration de Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: Frontend/package-lock.json
      
      - name: Construction du frontend
        working-directory: ./Frontend
        run: |
          echo "📦 Installation des dépendances..."
          npm install --legacy-peer-deps
          echo "🔑 Configuration des variables d'environnement..."
          cp .env.production .env
          echo "🚀 Construction de l'application React..."
          npm run build
          if [ $? -eq 0 ]; then
            echo "✅ Construction du frontend réussie!"
          else
            echo "❌ Échec de la construction du frontend, création d'une page d'attente temporaire..."
          fi

      - name: Vérification du build frontend
        id: check-frontend
        run: |
          if [ -f Frontend/dist/index.html ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "✅ Build React trouvé dans Frontend/dist/index.html"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "❌ Build React manquant dans Frontend/dist/index.html"
          fi

      - name: Créer une page d'attente si le frontend n'existe pas
        if: ${{ steps.check-frontend.outputs.exists != 'true' }}
        run: |
          mkdir -p Frontend/dist
          if [ -f "Frontend/public/waiting-page.html" ]; then
            cp Frontend/public/waiting-page.html Frontend/dist/index.html
            echo "✅ Page d'attente copiée avec succès dans Frontend/dist/index.html"
          else
            echo "<html><head><title>FloDrama - Site en maintenance</title></head><body style='background:#121118;color:white;font-family:sans-serif;text-align:center;padding-top:50px;'><h1 style='color:#3b82f6;'>FloDrama</h1><p>Site en cours de déploiement - Merci de votre patience</p></body></html>" > Frontend/dist/index.html
            echo "⚠️ Page d'attente simplifiée créée dans Frontend/dist/index.html"
          fi

      - name: Installation de Surge
        run: npm install -g surge

      - name: Déploiement sur flodrama.com
        run: |
          echo "🚀 Déploiement sur flodrama.com..."
          cd Frontend/dist
          surge --project ./ --domain flodrama.com --token ${{ secrets.SURGE_TOKEN }}
        env:
          SURGE_TOKEN: ${{ secrets.SURGE_TOKEN }}

      - name: Notification frontend
        run: echo "✅ Frontend déployé avec succès sur https://flodrama.com"
