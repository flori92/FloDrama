/**
 * Pipeline complet de scraping, enrichissement et distribution pour FloDrama
 * 
 * Ce script orchestre tout le processus de r√©cup√©ration, d'enrichissement
 * et de distribution des donn√©es pour FloDrama
 */

const fs = require('fs-extra');
const path = require('path');
const { exec } = require('child_process');
const axios = require('axios');
const CONFIG = require('./config');
const { enrichAllData } = require('./enrichissement');
const { generateAllFiles } = require('./distribution');

// Statistiques
const stats = {
  start_time: new Date(),
  end_time: null,
  duration_ms: 0,
  duration_formatted: '',
  scraping: {
    sources_processed: 0,
    sources_failed: 0,
    total_items: 0
  },
  enrichment: {
    items_processed: 0,
    items_enriched: 0,
    items_failed: 0
  },
  distribution: {
    categories_processed: 0,
    files_generated: 0
  }
};

/**
 * Ex√©cute une commande shell
 * @param {string} command - Commande √† ex√©cuter
 * @param {string} cwd - R√©pertoire de travail
 * @returns {Promise<{stdout: string, stderr: string}>} - R√©sultat de la commande
 */
function executeCommand(command, cwd = process.cwd()) {
  return new Promise((resolve, reject) => {
    exec(command, { cwd }, (error, stdout, stderr) => {
      if (error) {
        reject(error);
        return;
      }
      resolve({ stdout, stderr });
    });
  });
}

/**
 * Formate une dur√©e en millisecondes en format lisible
 * @param {number} ms - Dur√©e en millisecondes
 * @returns {string} - Dur√©e format√©e
 */
function formatDuration(ms) {
  const seconds = Math.floor(ms / 1000);
  const minutes = Math.floor(seconds / 60);
  const hours = Math.floor(minutes / 60);
  
  if (hours > 0) {
    return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
  } else if (minutes > 0) {
    return `${minutes}m ${seconds % 60}s`;
  } else {
    return `${seconds}s`;
  }
}

/**
 * Envoie une notification Discord
 * @param {string} message - Message √† envoyer
 * @param {string} title - Titre du message
 * @param {string} color - Couleur de l'embed (en hexad√©cimal)
 * @returns {Promise<boolean>} - Succ√®s de l'envoi
 */
async function sendDiscordNotification(message, title = 'FloDrama Scraping', color = '#00ff00') {
  try {
    if (!CONFIG.MONITORING.discordWebhook) {
      console.log('[NOTIFICATION] Webhook Discord non configur√©');
      return false;
    }
    
    const payload = {
      embeds: [
        {
          title,
          description: message,
          color: parseInt(color.replace('#', ''), 16),
          timestamp: new Date().toISOString()
        }
      ]
    };
    
    await axios.post(CONFIG.MONITORING.discordWebhook, payload);
    console.log('[NOTIFICATION] Notification Discord envoy√©e');
    return true;
  } catch (error) {
    console.error(`[NOTIFICATION] Erreur lors de l'envoi de la notification Discord: ${error.message}`);
    return false;
  }
}

/**
 * √âtape 1: Scraping des donn√©es
 */
async function runScraping() {
  console.log('='.repeat(80));
  console.log('√âTAPE 1: SCRAPING DES DONN√âES');
  console.log('='.repeat(80));
  
  try {
    // Cr√©er les r√©pertoires n√©cessaires
    await fs.ensureDir(CONFIG.TEMP_DIR);
    
    // Ex√©cuter le script de scraping pour chaque cat√©gorie
    for (const category of CONFIG.CATEGORIES) {
      console.log(`\nüîç Scraping des sources de ${category.toUpperCase()}...`);
      
      // R√©cup√©rer les sources de la cat√©gorie
      const sources = CONFIG.SOURCES[category] || [];
      
      if (sources.length === 0) {
        console.warn(`‚ö†Ô∏è Aucune source d√©finie pour la cat√©gorie ${category}`);
        continue;
      }
      
      // Trier les sources par priorit√©
      sources.sort((a, b) => a.priority - b.priority);
      
      // Scraper chaque source
      for (const source of sources) {
        console.log(`\nüîç Scraping de ${source.name} (cat√©gorie: ${category})...`);
        
        try {
          // Ex√©cuter le script de scraping
          const { stdout, stderr } = await executeCommand(
            `node ./cloudflare/scraping/src/cli-scraper.js --source=${source.name} --limit=${source.minItems} --output=${CONFIG.TEMP_DIR} --debug --save`,
            process.cwd()
          );
          
          // V√©rifier si le scraping a r√©ussi
          if (stderr && stderr.includes('Erreur')) {
            console.error(`‚ùå √âchec du scraping de ${source.name}: ${stderr}`);
            stats.scraping.sources_failed++;
          } else {
            console.log(`‚úÖ Scraping de ${source.name} termin√© avec succ√®s`);
            stats.scraping.sources_processed++;
            
            // Extraire le nombre d'√©l√©ments r√©cup√©r√©s
            const match = stdout.match(/(\d+) √©l√©ments trouv√©s/);
            if (match) {
              const itemCount = parseInt(match[1]);
              stats.scraping.total_items += itemCount;
              console.log(`üì¶ ${itemCount} √©l√©ments r√©cup√©r√©s pour ${source.name}`);
            }
          }
        } catch (error) {
          console.error(`‚ùå Erreur lors du scraping de ${source.name}: ${error.message}`);
          stats.scraping.sources_failed++;
        }
      }
    }
    
    console.log('\n‚úÖ Scraping termin√©');
    console.log(`üìä ${stats.scraping.sources_processed} sources trait√©es, ${stats.scraping.sources_failed} √©checs, ${stats.scraping.total_items} √©l√©ments r√©cup√©r√©s`);
    
    return true;
  } catch (error) {
    console.error(`‚ùå Erreur lors du scraping: ${error.message}`);
    return false;
  }
}

/**
 * √âtape 2: Enrichissement des donn√©es
 */
async function runEnrichment() {
  console.log('\n' + '='.repeat(80));
  console.log('√âTAPE 2: ENRICHISSEMENT DES DONN√âES');
  console.log('='.repeat(80));
  
  try {
    // Cr√©er les r√©pertoires n√©cessaires
    await fs.ensureDir(CONFIG.OUTPUT_DIR);
    
    // Enrichir les donn√©es
    const success = await enrichAllData(true);
    
    if (success) {
      console.log('\n‚úÖ Enrichissement termin√© avec succ√®s');
      
      // Compter les √©l√©ments enrichis
      let totalItems = 0;
      let enrichedItems = 0;
      
      // Parcourir les fichiers enrichis
      const files = await fs.readdir(CONFIG.OUTPUT_DIR);
      const enrichedFiles = files.filter(file => file.endsWith('_enriched.json'));
      
      for (const file of enrichedFiles) {
        try {
          const filePath = path.join(CONFIG.OUTPUT_DIR, file);
          const data = await fs.readJson(filePath);
          
          if (Array.isArray(data)) {
            totalItems += data.length;
            
            // Compter les √©l√©ments avec des donn√©es enrichies (poster, backdrop, trailer)
            const enriched = data.filter(item => item.poster && item.backdrop && item.trailer);
            enrichedItems += enriched.length;
          }
        } catch (error) {
          console.error(`‚ùå Erreur lors de la lecture de ${file}: ${error.message}`);
        }
      }
      
      stats.enrichment.items_processed = totalItems;
      stats.enrichment.items_enriched = enrichedItems;
      stats.enrichment.items_failed = totalItems - enrichedItems;
      
      console.log(`üìä ${enrichedItems}/${totalItems} √©l√©ments enrichis (${Math.round(enrichedItems / totalItems * 100)}%)`);
    } else {
      console.error('‚ùå √âchec de l\'enrichissement des donn√©es');
    }
    
    return success;
  } catch (error) {
    console.error(`‚ùå Erreur lors de l'enrichissement: ${error.message}`);
    return false;
  }
}

/**
 * √âtape 3: Distribution des donn√©es
 */
async function runDistribution() {
  console.log('\n' + '='.repeat(80));
  console.log('√âTAPE 3: DISTRIBUTION DES DONN√âES');
  console.log('='.repeat(80));
  
  try {
    // Cr√©er les r√©pertoires n√©cessaires
    await fs.ensureDir(CONFIG.OUTPUT_DIR);
    
    // G√©n√©rer les fichiers
    const success = await generateAllFiles(true);
    
    if (success) {
      console.log('\n‚úÖ Distribution termin√©e avec succ√®s');
      
      // Compter les fichiers g√©n√©r√©s
      let fileCount = 0;
      
      // Compter les fichiers dans chaque cat√©gorie
      for (const category of CONFIG.CATEGORIES) {
        const categoryDir = path.join(CONFIG.OUTPUT_DIR, category);
        
        if (await fs.pathExists(categoryDir)) {
          const files = await fs.readdir(categoryDir);
          fileCount += files.length;
          stats.distribution.categories_processed++;
        }
      }
      
      // Ajouter les fichiers √† la racine
      const rootFiles = await fs.readdir(CONFIG.OUTPUT_DIR);
      const jsonRootFiles = rootFiles.filter(file => file.endsWith('.json') && !file.includes('_enriched'));
      fileCount += jsonRootFiles.length;
      
      stats.distribution.files_generated = fileCount;
      
      console.log(`üìä ${fileCount} fichiers g√©n√©r√©s pour ${stats.distribution.categories_processed} cat√©gories`);
    } else {
      console.error('‚ùå √âchec de la distribution des donn√©es');
    }
    
    return success;
  } catch (error) {
    console.error(`‚ùå Erreur lors de la distribution: ${error.message}`);
    return false;
  }
}

/**
 * Fonction principale
 */
async function main() {
  console.log('='.repeat(80));
  console.log(`FloDrama - Pipeline Complet de Scraping`);
  console.log('='.repeat(80));
  console.log(`Date: ${new Date().toISOString()}`);
  console.log(`R√©pertoire de sortie: ${CONFIG.OUTPUT_DIR}`);
  console.log(`Cat√©gories: ${CONFIG.CATEGORIES.join(', ')}`);
  console.log('='.repeat(80));
  
  try {
    // √âtape 1: Scraping
    const scrapingSuccess = await runScraping();
    
    // √âtape 2: Enrichissement
    const enrichmentSuccess = await runEnrichment();
    
    // √âtape 3: Distribution
    const distributionSuccess = await runDistribution();
    
    // Calculer la dur√©e totale
    stats.end_time = new Date();
    stats.duration_ms = stats.end_time - stats.start_time;
    stats.duration_formatted = formatDuration(stats.duration_ms);
    
    // Afficher le r√©sum√©
    console.log('\n' + '='.repeat(80));
    console.log('R√âSUM√â DU PIPELINE');
    console.log('='.repeat(80));
    console.log(`‚è±Ô∏è Dur√©e totale: ${stats.duration_formatted}`);
    console.log('\nüìä Scraping:');
    console.log(`- Sources trait√©es: ${stats.scraping.sources_processed}`);
    console.log(`- Sources en √©chec: ${stats.scraping.sources_failed}`);
    console.log(`- √âl√©ments r√©cup√©r√©s: ${stats.scraping.total_items}`);
    console.log('\nüìä Enrichissement:');
    console.log(`- √âl√©ments trait√©s: ${stats.enrichment.items_processed}`);
    console.log(`- √âl√©ments enrichis: ${stats.enrichment.items_enriched}`);
    console.log(`- √âl√©ments en √©chec: ${stats.enrichment.items_failed}`);
    console.log('\nüìä Distribution:');
    console.log(`- Cat√©gories trait√©es: ${stats.distribution.categories_processed}`);
    console.log(`- Fichiers g√©n√©r√©s: ${stats.distribution.files_generated}`);
    
    // D√©terminer le statut global
    const globalSuccess = scrapingSuccess && enrichmentSuccess && distributionSuccess;
    
    if (globalSuccess) {
      console.log('\n‚úÖ Pipeline termin√© avec succ√®s');
      
      // Envoyer une notification de succ√®s
      await sendDiscordNotification(
        `‚úÖ Pipeline de scraping termin√© avec succ√®s en ${stats.duration_formatted}\n` +
        `üìä ${stats.scraping.total_items} √©l√©ments r√©cup√©r√©s, ${stats.enrichment.items_enriched} enrichis, ${stats.distribution.files_generated} fichiers g√©n√©r√©s`,
        '‚úÖ FloDrama Scraping - Succ√®s',
        '#00ff00'
      );
    } else {
      console.error('\n‚ùå Pipeline termin√© avec des erreurs');
      
      // Envoyer une notification d'erreur
      await sendDiscordNotification(
        `‚ùå Pipeline de scraping termin√© avec des erreurs en ${stats.duration_formatted}\n` +
        `üìä ${stats.scraping.sources_failed} sources en √©chec, ${stats.enrichment.items_failed} √©l√©ments non enrichis`,
        '‚ùå FloDrama Scraping - Erreur',
        '#ff0000'
      );
    }
    
    return globalSuccess;
  } catch (error) {
    console.error(`‚ùå Erreur fatale: ${error.message}`);
    
    // Envoyer une notification d'erreur fatale
    await sendDiscordNotification(
      `‚ùå Erreur fatale lors du pipeline de scraping: ${error.message}`,
      '‚ùå FloDrama Scraping - Erreur Fatale',
      '#ff0000'
    );
    
    return false;
  }
}

// Ex√©cuter la fonction principale
main()
  .then(success => {
    process.exit(success ? 0 : 1);
  })
  .catch(error => {
    console.error('Erreur non g√©r√©e:', error);
    process.exit(1);
  });
