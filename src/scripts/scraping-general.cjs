/**
 * Script de scraping g√©n√©ral pour FloDrama
 * 
 * Ce script r√©cup√®re toutes les m√©tadonn√©es possibles (dramas, films, Bollywood, anim√©s)
 * et les stocke dans un fichier JSON pour alimenter FloDrama en production.
 */

const fs = require('fs');
const path = require('path');
const SmartScrapingService = require('../services/SmartScrapingService.js');

// Configuration
const CONFIG = {
  // Nombre de pages √† r√©cup√©rer pour chaque cat√©gorie
  pageCount: 3,
  
  // R√©pertoire de sortie pour les donn√©es scrap√©es
  outputDir: path.join(__dirname, '../../data'),
  
  // Pr√©fixe pour les fichiers de sortie
  filePrefix: `${new Date().toISOString().split('T')[0]}_flodrama`,
  
  // Termes de recherche populaires pour enrichir les donn√©es
  searchTerms: [
    // Dramas cor√©ens populaires
    'squid game', 'vincenzo', 'crash landing on you', 'itaewon class', 'kingdom',
    'hospital playlist', 'true beauty', 'goblin', 'descendants of the sun',
    
    // Anim√©s populaires
    'attack on titan', 'demon slayer', 'jujutsu kaisen', 'my hero academia',
    'one piece', 'naruto', 'tokyo revengers', 'hunter x hunter',
    
    // Films populaires
    'parasite', 'train to busan', 'the handmaiden', 'oldboy',
    
    // Bollywood
    'rrr', 'bahubali', 'dangal', 'pk', '3 idiots'
  ],
  
  // D√©lai entre les requ√™tes (en ms) pour √©viter d'√™tre bloqu√©
  requestDelay: 3000,
  
  // Nombre maximum de tentatives pour chaque requ√™te
  maxRetries: 3,
  
  // Timeout pour chaque requ√™te (en ms)
  requestTimeout: 15000,
  
  // Activer/d√©sactiver le t√©l√©chargement des images
  downloadImages: false
};

// Fonction utilitaire pour attendre un certain temps
const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms));

// Fonction pour cr√©er le r√©pertoire de sortie s'il n'existe pas
const ensureOutputDir = () => {
  if (!fs.existsSync(CONFIG.outputDir)) {
    fs.mkdirSync(CONFIG.outputDir, { recursive: true });
    console.log(`‚úÖ R√©pertoire de sortie cr√©√©: ${CONFIG.outputDir}`);
  }
};

// Fonction pour sauvegarder les donn√©es dans un fichier JSON
const saveToJson = (data, category) => {
  const filename = `${CONFIG.filePrefix}_${category}.json`;
  const filepath = path.join(CONFIG.outputDir, filename);
  
  fs.writeFileSync(filepath, JSON.stringify(data, null, 2), 'utf8');
  console.log(`‚úÖ Donn√©es sauvegard√©es dans: ${filepath}`);
  
  return filepath;
};

// Fonction pour r√©cup√©rer les dramas populaires
const scrapeDramas = async () => {
  console.log('üîç R√©cup√©ration des dramas populaires...');
  
  try {
    // Ajouter un timeout pour √©viter que la requ√™te ne reste bloqu√©e
    const timeoutPromise = new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Timeout')), CONFIG.requestTimeout)
    );
    
    const dramasPromise = SmartScrapingService.getPopularDramas(CONFIG.pageCount);
    const dramas = await Promise.race([dramasPromise, timeoutPromise]);
    
    console.log(`‚úÖ ${dramas.length} dramas populaires r√©cup√©r√©s`);
    return dramas;
  } catch (error) {
    console.error('‚ùå Erreur lors de la r√©cup√©ration des dramas populaires:', error.message);
    return [];
  }
};

// Fonction pour r√©cup√©rer les films populaires
const scrapeMovies = async () => {
  console.log('üîç R√©cup√©ration des films populaires...');
  
  try {
    // Ajouter un timeout pour √©viter que la requ√™te ne reste bloqu√©e
    const timeoutPromise = new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Timeout')), CONFIG.requestTimeout)
    );
    
    const moviesPromise = SmartScrapingService.getPopularMovies(CONFIG.pageCount);
    const movies = await Promise.race([moviesPromise, timeoutPromise]);
    
    console.log(`‚úÖ ${movies.length} films populaires r√©cup√©r√©s`);
    return movies;
  } catch (error) {
    console.error('‚ùå Erreur lors de la r√©cup√©ration des films populaires:', error.message);
    return [];
  }
};

// Fonction pour r√©cup√©rer les K-shows populaires
const scrapeKshows = async () => {
  console.log('üîç R√©cup√©ration des K-shows populaires...');
  
  try {
    // Ajouter un timeout pour √©viter que la requ√™te ne reste bloqu√©e
    const timeoutPromise = new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Timeout')), CONFIG.requestTimeout)
    );
    
    const kshowsPromise = SmartScrapingService.getPopularKshows(CONFIG.pageCount);
    const kshows = await Promise.race([kshowsPromise, timeoutPromise]);
    
    console.log(`‚úÖ ${kshows.length} K-shows populaires r√©cup√©r√©s`);
    return kshows;
  } catch (error) {
    console.error('‚ùå Erreur lors de la r√©cup√©ration des K-shows populaires:', error.message);
    return [];
  }
};

// Fonction pour r√©cup√©rer les anim√©s populaires
const scrapeAnimes = async () => {
  console.log('üîç R√©cup√©ration des anim√©s populaires...');
  
  try {
    // Ajouter un timeout pour √©viter que la requ√™te ne reste bloqu√©e
    const timeoutPromise = new Promise((_, reject) => 
      setTimeout(() => reject(new Error('Timeout')), CONFIG.requestTimeout)
    );
    
    const animesPromise = SmartScrapingService.getPopularAnimes(CONFIG.pageCount);
    const animes = await Promise.race([animesPromise, timeoutPromise]);
    
    console.log(`‚úÖ ${animes.length} anim√©s populaires r√©cup√©r√©s`);
    return animes;
  } catch (error) {
    console.error('‚ùå Erreur lors de la r√©cup√©ration des anim√©s populaires:', error.message);
    return [];
  }
};

// Fonction pour enrichir les donn√©es avec des recherches sp√©cifiques
const enrichWithSearches = async (existingData) => {
  console.log('üîç Enrichissement des donn√©es avec des recherches sp√©cifiques...');
  
  const searchResults = [];
  const existingTitles = new Set(existingData.map(item => item.title?.toLowerCase()));
  
  for (const term of CONFIG.searchTerms) {
    console.log(`  üîé Recherche pour: "${term}"...`);
    
    try {
      // Ajouter un timeout pour √©viter que la requ√™te ne reste bloqu√©e
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Timeout')), CONFIG.requestTimeout)
      );
      
      const resultsPromise = SmartScrapingService.searchAll(term);
      const results = await Promise.race([resultsPromise, timeoutPromise]);
      
      // Fusionner tous les r√©sultats
      const allResults = [
        ...(results.dramas || []),
        ...(results.animes || []),
        ...(results.movies || [])
      ];
      
      // Filtrer les doublons
      const newResults = allResults.filter(item => 
        item.title && !existingTitles.has(item.title.toLowerCase())
      );
      
      if (newResults.length > 0) {
        console.log(`  ‚úÖ ${newResults.length} nouveaux r√©sultats trouv√©s pour "${term}"`);
        searchResults.push(...newResults);
        
        // Ajouter les nouveaux titres √† l'ensemble des titres existants
        newResults.forEach(item => {
          if (item.title) {
            existingTitles.add(item.title.toLowerCase());
          }
        });
      } else {
        console.log(`  ‚ÑπÔ∏è Aucun nouveau r√©sultat pour "${term}"`);
      }
      
      // Attendre entre chaque recherche pour √©viter d'√™tre bloqu√©
      await sleep(CONFIG.requestDelay);
    } catch (error) {
      console.error(`  ‚ùå Erreur lors de la recherche pour "${term}":`, error.message);
    }
  }
  
  console.log(`‚úÖ ${searchResults.length} nouveaux √©l√©ments ajout√©s par recherche`);
  return searchResults;
};

// Fonction pour t√©l√©charger les images et les stocker localement
const downloadImages = async (data) => {
  console.log('üñºÔ∏è T√©l√©chargement des images...');
  
  const imagesDir = path.join(CONFIG.outputDir, 'images');
  if (!fs.existsSync(imagesDir)) {
    fs.mkdirSync(imagesDir, { recursive: true });
  }
  
  let successCount = 0;
  let errorCount = 0;
  
  // Traiter les √©l√©ments par lots pour √©viter de surcharger le syst√®me
  const batchSize = 10;
  const batches = Math.ceil(data.length / batchSize);
  
  for (let i = 0; i < batches; i++) {
    const batch = data.slice(i * batchSize, (i + 1) * batchSize);
    const batchResults = await Promise.all(batch.map(async (item) => {
      if (!item.image) return { item, success: false, processed: false };
      
      try {
        const imageUrl = item.image;
        const imageId = `${item.source}-${item.id || Math.random().toString(36).substring(2, 10)}`;
        const extension = imageUrl.split('.').pop().split('?')[0] || 'jpg';
        const filename = `${imageId}.${extension}`;
        const filepath = path.join(imagesDir, filename);
        
        // V√©rifier si l'image existe d√©j√†
        if (fs.existsSync(filepath)) {
          item.localImage = `images/${filename}`;
          return { item, success: true, processed: false };
        }
        
        // T√©l√©charger l'image
        const response = await SmartScrapingService.proxyService.fetch(imageUrl, {
          headers: SmartScrapingService.fingerprintService.getHeaders()
        });
        
        if (!response.ok) {
          throw new Error(`Statut HTTP: ${response.status}`);
        }
        
        const buffer = await response.buffer();
        fs.writeFileSync(filepath, buffer);
        
        // Mettre √† jour l'√©l√©ment avec le chemin local de l'image
        item.localImage = `images/${filename}`;
        return { item, success: true, processed: true };
      } catch (error) {
        console.error(`  ‚ùå Erreur lors du t√©l√©chargement de l'image pour ${item.title}:`, error.message);
        return { item, success: false, processed: true, error: error.message };
      }
    }));
    
    // Mettre √† jour les compteurs en dehors de la fonction de rappel
    for (const result of batchResults) {
      if (result.processed) {
        if (result.success) successCount++;
        else errorCount++;
      }
    }
    
    // Mettre √† jour les donn√©es
    for (let j = 0; j < batchResults.length; j++) {
      batch[j] = batchResults[j].item;
    }
    
    // Attendre entre chaque lot pour √©viter d'√™tre bloqu√©
    if (i < batches - 1) {
      await sleep(CONFIG.requestDelay);
    }
  }
  
  console.log(`‚úÖ Images t√©l√©charg√©es: ${successCount} r√©ussies, ${errorCount} √©chou√©es`);
  return data;
};

// Fonction pour g√©n√©rer un fichier de m√©tadonn√©es consolid√©
const generateMetadataFile = (data) => {
  const metadata = {
    totalItems: data.length,
    categories: {
      dramas: data.filter(item => item.type === 'drama').length,
      movies: data.filter(item => item.type === 'movie').length,
      animes: data.filter(item => item.type === 'anime').length,
      kshows: data.filter(item => item.type === 'kshow').length,
      other: data.filter(item => !item.type || !['drama', 'movie', 'anime', 'kshow'].includes(item.type)).length
    },
    sources: {},
    generatedAt: new Date().toISOString(),
    version: '1.0.0'
  };
  
  // Compter les √©l√©ments par source
  data.forEach(item => {
    if (item.source) {
      metadata.sources[item.source] = (metadata.sources[item.source] || 0) + 1;
    }
  });
  
  const filename = `${CONFIG.filePrefix}_metadata.json`;
  const filepath = path.join(CONFIG.outputDir, filename);
  
  fs.writeFileSync(filepath, JSON.stringify(metadata, null, 2), 'utf8');
  console.log(`‚úÖ M√©tadonn√©es sauvegard√©es dans: ${filepath}`);
  
  return metadata;
};

// Fonction principale pour ex√©cuter le scraping g√©n√©ral
async function runGeneralScraping() {
  console.log('üöÄ D√©marrage du scraping g√©n√©ral pour FloDrama...\n');
  
  // √âtape 1: Cr√©er le r√©pertoire de sortie
  ensureOutputDir();
  
  // √âtape 2: R√©cup√©rer les donn√©es de base
  const dramas = await scrapeDramas();
  await sleep(CONFIG.requestDelay);
  
  const movies = await scrapeMovies();
  await sleep(CONFIG.requestDelay);
  
  const kshows = await scrapeKshows();
  await sleep(CONFIG.requestDelay);
  
  const animes = await scrapeAnimes();
  await sleep(CONFIG.requestDelay);
  
  // √âtape 3: Fusionner les donn√©es de base
  let allData = [
    ...dramas.map(item => ({ ...item, type: 'drama' })),
    ...movies.map(item => ({ ...item, type: 'movie' })),
    ...kshows.map(item => ({ ...item, type: 'kshow' })),
    ...animes.map(item => ({ ...item, type: 'anime' }))
  ];
  
  console.log(`‚úÖ Donn√©es de base r√©cup√©r√©es: ${allData.length} √©l√©ments au total`);
  
  // √âtape 4: Enrichir avec des recherches sp√©cifiques
  const searchResults = await enrichWithSearches(allData);
  allData = [...allData, ...searchResults];
  
  // √âtape 5: D√©dupliquer les donn√©es
  const uniqueData = [];
  const seenTitles = new Set();
  
  allData.forEach(item => {
    if (item.title && !seenTitles.has(item.title.toLowerCase())) {
      uniqueData.push(item);
      seenTitles.add(item.title.toLowerCase());
    }
  });
  
  console.log(`‚úÖ Donn√©es d√©dupliqu√©es: ${uniqueData.length} √©l√©ments uniques`);
  
  // √âtape 6: T√©l√©charger les images si activ√©
  let dataWithImages = uniqueData;
  if (CONFIG.downloadImages) {
    dataWithImages = await downloadImages(uniqueData);
  } else {
    console.log('üñºÔ∏è T√©l√©chargement des images d√©sactiv√©');
  }
  
  // √âtape 7: Sauvegarder les donn√©es par cat√©gorie
  const dramasData = dataWithImages.filter(item => item.type === 'drama');
  const moviesData = dataWithImages.filter(item => item.type === 'movie');
  const kshowsData = dataWithImages.filter(item => item.type === 'kshow');
  const animesData = dataWithImages.filter(item => item.type === 'anime');
  
  saveToJson(dramasData, 'dramas');
  saveToJson(moviesData, 'movies');
  saveToJson(kshowsData, 'kshows');
  saveToJson(animesData, 'animes');
  saveToJson(dataWithImages, 'all');
  
  // √âtape 8: G√©n√©rer un fichier de m√©tadonn√©es
  generateMetadataFile(dataWithImages);
  
  console.log('\nüèÅ Scraping g√©n√©ral termin√© avec succ√®s!');
  console.log(`üìä Statistiques:`);
  console.log(`  - Dramas: ${dramasData.length}`);
  console.log(`  - Films: ${moviesData.length}`);
  console.log(`  - K-shows: ${kshowsData.length}`);
  console.log(`  - Anim√©s: ${animesData.length}`);
  console.log(`  - Total: ${dataWithImages.length}`);
  
  // √âtape 9: Afficher les instructions pour d√©ployer les donn√©es sur AWS
  console.log('\nüì§ Pour d√©ployer ces donn√©es sur AWS:');
  console.log(`  1. Compresser le dossier: zip -r ${CONFIG.filePrefix}.zip ${CONFIG.outputDir}`);
  console.log('  2. T√©l√©charger le fichier ZIP sur S3: aws s3 cp flodrama-data.zip s3://flodrama-assets/data/');
  console.log('  3. Mettre √† jour la r√©f√©rence dans l\'application: AWS_DATA_URL=https://flodrama-assets.s3.amazonaws.com/data/latest.json');
}

// Ex√©cution du scraping g√©n√©ral
runGeneralScraping().catch(error => {
  console.error('‚ùå Erreur lors du scraping g√©n√©ral:', error.message);
});
