// Script de scraping avec SmartScrapingService pour alimenter FloDrama en contenu
import { SmartScrapingService } from '../features/scraping/services/SmartScrapingService.js';
import ContentDataService from '../services/content/ContentDataService.js';

/**
 * Fonction principale pour lancer le scraping et alimenter la base de donnÃ©es
 */
async function lancerScrapingProduction() {
  console.log('ğŸš€ Lancement du scraping intelligent FloDrama (production) ...');

  try {
    // Instancier les services
    const smartScrapingService = new SmartScrapingService();
    const contentDataService = new ContentDataService();
    
    // Configuration du service de scraping
    await smartScrapingService.configure({
      proxy: {
        useProxy: true,
        timeout: 30000,
        maxRetries: 3
      },
      categorization: {
        enableAI: false,
        defaultType: 'drama'
      },
      useCache: true,
      cacheFile: 'scraping-cache.json'
    });
    
    // Ã‰couter les Ã©vÃ©nements du service de scraping
    smartScrapingService.events.on('updateStart', () => {
      console.log('ğŸ“¡ DÃ©but de la mise Ã  jour de la base de donnÃ©es...');
    });
    
    smartScrapingService.events.on('updateComplete', (data) => {
      console.log(`âœ… Mise Ã  jour terminÃ©e avec ${data.count} Ã©lÃ©ments rÃ©cupÃ©rÃ©s`);
    });
    
    smartScrapingService.events.on('updateError', (error) => {
      console.error('âŒ Erreur lors de la mise Ã  jour:', error.message);
    });
    
    smartScrapingService.events.on('scrapeError', (data) => {
      console.warn(`âš ï¸ Erreur lors du scraping de ${data.source}:`, data.error.message);
    });
    
    // Lancer la mise Ã  jour de la base de donnÃ©es
    console.log('ğŸ” RÃ©cupÃ©ration des contenus depuis toutes les sources...');
    const allResults = await smartScrapingService.updateContentDatabase();
    
    // Vider le cache pour s'assurer que les nouvelles donnÃ©es seront utilisÃ©es
    await contentDataService.clearCache();
    
    // IntÃ©grer les donnÃ©es scrapÃ©es dans le ContentDataService
    console.log('ğŸ“¥ IntÃ©gration des donnÃ©es scrapÃ©es dans la base de donnÃ©es...');
    
    // CrÃ©er une nouvelle mÃ©thode dans ContentDataService pour intÃ©grer directement les donnÃ©es scrapÃ©es
    contentDataService.integrateScrapedContent = function(scrapedContent) {
        // Remplacer le cache interne par les donnÃ©es scrapÃ©es
        this.cache.allContent = scrapedContent;
        this.cache.lastFetched = Date.now();
        
        // Mettre Ã  jour les caches secondaires
        this.updateSecondaryCache(scrapedContent);
        
        // Sauvegarder dans le stockage persistant si disponible
        if (this.storageService) {
            this.storageService.set('all_content', scrapedContent);
            this.storageService.set('content_timestamp', Date.now());
        }
        
        // Remplacer la mÃ©thode fetchMockContent pour qu'elle retourne les donnÃ©es scrapÃ©es
        this.fetchMockContent = async function() {
            console.log('Utilisation des donnÃ©es scrapÃ©es au lieu des mocks');
            return scrapedContent;
        };
        
        return scrapedContent.length;
    };
    
    // IntÃ©grer les donnÃ©es scrapÃ©es
    const integratedCount = contentDataService.integrateScrapedContent(allResults);
    console.log(`ğŸ“¥ ${integratedCount} Ã©lÃ©ments intÃ©grÃ©s dans la base de donnÃ©es`);
    
    // Afficher un rÃ©sumÃ© des rÃ©sultats
    const resultsByType = {};
    allResults.forEach(item => {
      const type = item.type || 'unknown';
      resultsByType[type] = (resultsByType[type] || 0) + 1;
    });
    
    console.log('\nğŸ“Š RÃ©sumÃ© du scraping:');
    console.log(`ğŸ“Œ Total: ${allResults.length} Ã©lÃ©ments rÃ©cupÃ©rÃ©s`);
    
    Object.entries(resultsByType).forEach(([type, count]) => {
      console.log(`ğŸ“Œ ${type}: ${count} Ã©lÃ©ments`);
    });
    
    // VÃ©rification finale du contenu disponible
    const allContent = await contentDataService.getAllContent({ forceRefresh: true });
    console.log(`\nğŸ“š Contenu disponible aprÃ¨s scraping : ${allContent.length} Ã©lÃ©ments`);
    
    return {
      success: true,
      totalItems: allResults.length,
      types: resultsByType
    };
  } catch (error) {
    console.error('âŒ Erreur globale lors du scraping:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// ExÃ©cuter le script
lancerScrapingProduction()
  .then(result => {
    if (result.success) {
      console.log('âœ¨ Scraping terminÃ© avec succÃ¨s!');
    } else {
      console.error('âŒ Ã‰chec du scraping:', result.error);
    }
  })
  .catch(error => {
    console.error('âŒ Erreur non gÃ©rÃ©e:', error);
  });
