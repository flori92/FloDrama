#!/bin/bash
# Script pour lancer le scraping avec le serveur local

# D√©finir les variables d'environnement
export RENDER_SERVICE_URL="http://localhost:3000"
export RENDER_API_KEY="rnd_DJfpQC9gEu4KgTRvX8iQzMXxrteP"
export USE_RELAY_SERVICE="true"
export DEBUG_MODE="true"

# V√©rifier si le serveur local est en cours d'ex√©cution
if ! curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer $RENDER_API_KEY" http://localhost:3000/status | grep -q "200"; then
  echo "üöÄ D√©marrage du serveur local..."
  node $(dirname "$0")/serveur-relay-local.js > $(dirname "$0")/relay-logs.txt 2>&1 &
  SERVER_PID=$!
  echo "‚úÖ Serveur local d√©marr√© avec PID $SERVER_PID"
  sleep 2 # Attendre que le serveur d√©marre
else
  echo "‚úÖ Serveur local d√©j√† en cours d'ex√©cution"
fi

# Ex√©cuter le script de scraping
echo "üîç D√©marrage du scraping..."
cd "$(dirname "$0")/../../"
node .github/scripts/stealth/scraper-optimise.js "$@"

# V√©rifier si des donn√©es ont √©t√© g√©n√©r√©es
if [ -d "./cloudflare/scraping/output" ] && [ "$(find ./cloudflare/scraping/output -name '*.json' | wc -l)" -gt 0 ]; then
  echo "‚úÖ Scraping termin√© avec succ√®s"
  
  # Enrichir les donn√©es si TMDB_API_KEY est d√©fini
  if [ -n "$TMDB_API_KEY" ]; then
    echo "üîç Enrichissement des donn√©es via TMDB..."
    node .github/scripts/enrichment/tmdb-enricher.js
    echo "‚úÖ Enrichissement termin√© avec succ√®s"
  fi
  
  # Importer les donn√©es dans D1 si demand√©
  if [ "$1" == "--import" ] || [ "$2" == "--import" ]; then
    echo "üì¶ Importation des donn√©es dans D1..."
    cd cloudflare/scraping
    node ./import-to-d1.js
    echo "‚úÖ Importation termin√©e avec succ√®s"
  fi
else
  echo "‚ö†Ô∏è Le scraping n'a pas g√©n√©r√© de donn√©es"
fi

echo "‚úÖ Processus termin√©"
