#!/bin/bash
# Script d'exÃ©cution locale du workflow de scraping FloDrama
# Ce script simule l'exÃ©cution du workflow GitHub Actions en local
# pour tester et dÃ©boguer le processus de scraping

# Couleurs pour les messages
ROUGE='\033[0;31m'
VERT='\033[0;32m'
JAUNE='\033[0;33m'
BLEU='\033[0;34m'
NC='\033[0m' # No Color

# Dossier racine du projet
PROJET_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
LOGS_DIR="${PROJET_DIR}/cloudflare/scraping/workflow-logs"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="${LOGS_DIR}/execution_locale_${TIMESTAMP}.log"

# Fonction pour logger les messages
log() {
  echo -e "${1}"
  echo "$(date +'[%Y-%m-%dT%H:%M:%S.%3NZ]') ${1}" | sed 's/\x1B\[[0-9;]\{1,\}[A-Za-z]//g' >> "${LOG_FILE}"
}

# Fonction pour afficher l'aide
afficher_aide() {
  echo "Usage: $0 [options]"
  echo ""
  echo "Options:"
  echo "  --sources=SOURCE1,SOURCE2    Sources Ã  scraper (sÃ©parÃ©es par des virgules)"
  echo "  --skip-scraping              Sauter l'Ã©tape de scraping"
  echo "  --skip-enrichment            Sauter l'Ã©tape d'enrichissement"
  echo "  --skip-distribution          Sauter l'Ã©tape de distribution"
  echo "  --debug                      Activer le mode debug"
  echo "  --use-relay                  Utiliser le service relais Render"
  echo "  --no-relay                   Ne pas utiliser le service relais Render"
  echo "  --help                       Afficher cette aide"
  echo ""
  echo "Exemple: $0 --sources=allocine-films,tmdb-films --debug --use-relay"
}

# CrÃ©er le dossier de logs s'il n'existe pas
mkdir -p "${LOGS_DIR}"

# Traiter les arguments
SOURCES=""
SKIP_SCRAPING=false
SKIP_ENRICHMENT=false
SKIP_DISTRIBUTION=false
DEBUG_MODE=false
USE_RELAY_SERVICE=true

for arg in "$@"; do
  case $arg in
    --sources=*)
      SOURCES="${arg#*=}"
      ;;
    --skip-scraping)
      SKIP_SCRAPING=true
      ;;
    --skip-enrichment)
      SKIP_ENRICHMENT=true
      ;;
    --skip-distribution)
      SKIP_DISTRIBUTION=true
      ;;
    --debug)
      DEBUG_MODE=true
      ;;
    --use-relay)
      USE_RELAY_SERVICE=true
      ;;
    --no-relay)
      USE_RELAY_SERVICE=false
      ;;
    --help)
      afficher_aide
      exit 0
      ;;
    *)
      echo -e "${ROUGE}Option inconnue: $arg${NC}"
      afficher_aide
      exit 1
      ;;
  esac
done

# Afficher la banniÃ¨re
echo -e "${BLEU}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${BLEU}â•‘                                                                â•‘${NC}"
echo -e "${BLEU}â•‘             EXÃ‰CUTION LOCALE DU WORKFLOW FLODRAMA             â•‘${NC}"
echo -e "${BLEU}â•‘                                                                â•‘${NC}"
echo -e "${BLEU}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Afficher la configuration
echo -e "${JAUNE}Configuration:${NC}"
echo -e "  ${JAUNE}Sources:${NC} ${SOURCES:-Toutes}"
echo -e "  ${JAUNE}Skip Scraping:${NC} ${SKIP_SCRAPING}"
echo -e "  ${JAUNE}Skip Enrichment:${NC} ${SKIP_ENRICHMENT}"
echo -e "  ${JAUNE}Skip Distribution:${NC} ${SKIP_DISTRIBUTION}"
echo -e "  ${JAUNE}Debug Mode:${NC} ${DEBUG_MODE}"
echo -e "  ${JAUNE}Use Relay Service:${NC} ${USE_RELAY_SERVICE}"
echo -e "  ${JAUNE}Log File:${NC} ${LOG_FILE}"
echo ""

# VÃ©rifier les dÃ©pendances
log "${JAUNE}ğŸ” VÃ©rification des dÃ©pendances...${NC}"
if ! command -v node &> /dev/null; then
  log "${ROUGE}âŒ Node.js n'est pas installÃ©. Veuillez l'installer pour continuer.${NC}"
  exit 1
fi

if ! command -v npm &> /dev/null; then
  log "${ROUGE}âŒ npm n'est pas installÃ©. Veuillez l'installer pour continuer.${NC}"
  exit 1
fi

# VÃ©rifier si les dÃ©pendances Node sont installÃ©es
if [ ! -d "${PROJET_DIR}/node_modules" ]; then
  log "${JAUNE}âš ï¸ Les dÃ©pendances Node ne semblent pas Ãªtre installÃ©es. Installation...${NC}"
  cd "${PROJET_DIR}" && npm install --ignore-scripts
  
  # Installation des dÃ©pendances spÃ©cifiques pour le scraping
  npm install --no-save fs-extra axios cheerio playwright playwright-extra playwright-extra-plugin-stealth
else
  log "${VERT}âœ… DÃ©pendances Node dÃ©jÃ  installÃ©es${NC}"
fi

# DÃ©finir les variables d'environnement
export DEBUG_MODE=${DEBUG_MODE}
export USE_RELAY_SERVICE=${USE_RELAY_SERVICE}
export RENDER_API_KEY="rnd_DJfpQC9gEu4KgTRvX8iQzMXxrteP"

# VÃ©rifier la clÃ© API TMDB
if [ -z "${TMDB_API_KEY}" ]; then
  log "${JAUNE}âš ï¸ Variable d'environnement TMDB_API_KEY non dÃ©finie${NC}"
  log "${JAUNE}âš ï¸ L'enrichissement des donnÃ©es pourrait Ã©chouer${NC}"
  
  # Demander la clÃ© API TMDB si nÃ©cessaire et si l'enrichissement n'est pas sautÃ©
  if [ "${SKIP_ENRICHMENT}" = false ]; then
    echo -n "Veuillez entrer votre clÃ© API TMDB (ou laissez vide pour continuer sans): "
    read -r TMDB_API_KEY
    export TMDB_API_KEY="${TMDB_API_KEY}"
  fi
fi

# VÃ©rification du service relais Render si activÃ©
if [ "${USE_RELAY_SERVICE}" = true ] && [ "${SKIP_SCRAPING}" = false ]; then
  log "${JAUNE}ğŸ”„ VÃ©rification de la disponibilitÃ© du service relais Render...${NC}"
  
  RELAY_STATUS=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer ${RENDER_API_KEY}" https://flodrama-scraper.onrender.com/status)
  
  if [ "${RELAY_STATUS}" = "200" ]; then
    log "${VERT}âœ… Service relais Render disponible${NC}"
  else
    log "${ROUGE}âš ï¸ Service relais Render indisponible (code: ${RELAY_STATUS}), utilisation du fallback local${NC}"
    export USE_RELAY_SERVICE=false
  fi
fi

# Ã‰tape de scraping
if [ "${SKIP_SCRAPING}" = false ]; then
  log "${JAUNE}ğŸ” DÃ©marrage du scraping...${NC}"
  
  # DÃ©terminer les sources Ã  scraper
  SOURCES_ARG=""
  if [ -n "${SOURCES}" ]; then
    SOURCES_ARG="--sources=${SOURCES}"
    log "${JAUNE}Sources spÃ©cifiÃ©es: ${SOURCES}${NC}"
  else
    log "${JAUNE}Scraping de toutes les sources${NC}"
  fi
  
  # ExÃ©cuter le script de scraping optimisÃ©
  cd "${PROJET_DIR}" && node .github/scripts/stealth/scraper-optimise.js ${SOURCES_ARG}
  SCRAPING_STATUS=$?
  
  # VÃ©rifier si des donnÃ©es ont Ã©tÃ© gÃ©nÃ©rÃ©es
  if [ ${SCRAPING_STATUS} -eq 0 ] && [ -d "${PROJET_DIR}/cloudflare/scraping/output" ] && [ "$(find "${PROJET_DIR}/cloudflare/scraping/output" -name '*.json' | wc -l)" -gt 0 ]; then
    log "${VERT}âœ… Scraping terminÃ© avec succÃ¨s${NC}"
    SCRAPING_SUCCESS=true
  else
    log "${ROUGE}âš ï¸ Le scraping n'a pas gÃ©nÃ©rÃ© de donnÃ©es, vÃ©rifiez les logs pour plus d'informations${NC}"
    SCRAPING_SUCCESS=false
  fi
else
  log "${JAUNE}â© Ã‰tape de scraping sautÃ©e${NC}"
  SCRAPING_SUCCESS=true
fi

# Ã‰tape d'enrichissement des donnÃ©es
if [ "${SKIP_ENRICHMENT}" = false ] && [ "${SCRAPING_SUCCESS}" = true ]; then
  log "${JAUNE}ğŸ” DÃ©marrage de l'enrichissement des donnÃ©es...${NC}"
  cd "${PROJET_DIR}" && node .github/scripts/enrichment/tmdb-enricher.js
  ENRICHMENT_STATUS=$?
  
  if [ ${ENRICHMENT_STATUS} -eq 0 ]; then
    log "${VERT}âœ… Enrichissement terminÃ© avec succÃ¨s${NC}"
    ENRICHMENT_SUCCESS=true
  else
    log "${ROUGE}âŒ Erreur lors de l'enrichissement des donnÃ©es${NC}"
    ENRICHMENT_SUCCESS=false
  fi
else
  if [ "${SKIP_ENRICHMENT}" = true ]; then
    log "${JAUNE}â© Ã‰tape d'enrichissement sautÃ©e${NC}"
  else
    log "${ROUGE}â© Ã‰tape d'enrichissement sautÃ©e car le scraping a Ã©chouÃ©${NC}"
  fi
  ENRICHMENT_SUCCESS=true
fi

# Ã‰tape de distribution des donnÃ©es
if [ "${SKIP_DISTRIBUTION}" = false ] && ([ "${SCRAPING_SUCCESS}" = true ] || [ "${SKIP_SCRAPING}" = true ]); then
  log "${JAUNE}ğŸ“¦ DÃ©marrage de la distribution des donnÃ©es...${NC}"
  
  # VÃ©rifier si wrangler est installÃ©
  if ! command -v wrangler &> /dev/null; then
    log "${JAUNE}âš ï¸ wrangler n'est pas installÃ©, installation...${NC}"
    npm install -g wrangler
  fi
  
  # VÃ©rifier les variables d'environnement Cloudflare
  if [ -z "${CLOUDFLARE_API_TOKEN}" ] || [ -z "${CLOUDFLARE_ACCOUNT_ID}" ]; then
    log "${JAUNE}âš ï¸ Variables d'environnement Cloudflare non dÃ©finies${NC}"
    log "${JAUNE}âš ï¸ La distribution vers Cloudflare D1 ne sera pas effectuÃ©e${NC}"
    log "${JAUNE}âš ï¸ Les fichiers SQL seront gÃ©nÃ©rÃ©s localement${NC}"
    
    # ExÃ©cuter uniquement la gÃ©nÃ©ration des fichiers SQL
    cd "${PROJET_DIR}/cloudflare/scraping" && node ./import-to-d1.js --local-only
  else
    # CrÃ©er la base de donnÃ©es D1 si elle n'existe pas
    cd "${PROJET_DIR}" && wrangler d1 create flodrama-content --json || echo "Base de donnÃ©es existe dÃ©jÃ "
    
    # ExÃ©cuter les migrations de schÃ©ma
    cd "${PROJET_DIR}/cloudflare/scraping" && wrangler d1 execute flodrama-content --file=./schema.sql
    
    # Importer les donnÃ©es
    cd "${PROJET_DIR}/cloudflare/scraping" && node ./import-to-d1.js
  fi
  
  log "${VERT}âœ… Distribution terminÃ©e avec succÃ¨s${NC}"
else
  if [ "${SKIP_DISTRIBUTION}" = true ]; then
    log "${JAUNE}â© Ã‰tape de distribution sautÃ©e${NC}"
  else
    log "${ROUGE}â© Ã‰tape de distribution sautÃ©e car le scraping a Ã©chouÃ©${NC}"
  fi
fi

# Afficher un rÃ©sumÃ©
echo ""
echo -e "${BLEU}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${BLEU}â•‘                         RÃ‰SUMÃ‰                                 â•‘${NC}"
echo -e "${BLEU}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

if [ "${SKIP_SCRAPING}" = false ]; then
  if [ "${SCRAPING_SUCCESS}" = true ]; then
    echo -e "${VERT}âœ… Scraping: SuccÃ¨s${NC}"
  else
    echo -e "${ROUGE}âŒ Scraping: Ã‰chec${NC}"
  fi
else
  echo -e "${JAUNE}â© Scraping: SautÃ©${NC}"
fi

if [ "${SKIP_ENRICHMENT}" = false ]; then
  if [ "${ENRICHMENT_SUCCESS}" = true ]; then
    echo -e "${VERT}âœ… Enrichissement: SuccÃ¨s${NC}"
  else
    echo -e "${ROUGE}âŒ Enrichissement: Ã‰chec${NC}"
  fi
else
  echo -e "${JAUNE}â© Enrichissement: SautÃ©${NC}"
fi

if [ "${SKIP_DISTRIBUTION}" = false ]; then
  echo -e "${VERT}âœ… Distribution: TerminÃ©e${NC}"
else
  echo -e "${JAUNE}â© Distribution: SautÃ©e${NC}"
fi

echo ""
echo -e "${VERT}Logs disponibles dans: ${LOG_FILE}${NC}"
echo ""

# Proposer d'analyser les logs
echo -e "${JAUNE}Souhaitez-vous analyser les logs pour dÃ©tecter les problÃ¨mes potentiels? (o/n)${NC}"
read -r ANALYSE_LOGS

if [ "${ANALYSE_LOGS}" = "o" ] || [ "${ANALYSE_LOGS}" = "O" ] || [ "${ANALYSE_LOGS}" = "oui" ]; then
  log "${JAUNE}ğŸ” Analyse des logs...${NC}"
  cd "${PROJET_DIR}" && node cloudflare/scraping/analyse-workflow-logs.js
  
  echo -e "${VERT}âœ… Analyse terminÃ©e. Consultez le rapport dans: ${LOGS_DIR}/analyse-resultats.md${NC}"
fi

echo -e "${VERT}âœ… ExÃ©cution locale du workflow terminÃ©e${NC}"
