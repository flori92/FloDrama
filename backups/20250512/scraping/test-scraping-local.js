/**
 * Script de test de scraping local pour FloDrama
 * 
 * Ce script permet de tester le scraping en local et de comparer les performances
 * entre le scraping local et le service relais Render.
 * 
 * @author FloDrama Team
 * @version 1.0.0
 */

const fs = require('fs-extra');
const path = require('path');
const axios = require('axios');
const { execSync } = require('child_process');

// Configuration
const RENDER_SERVICE_URL = process.env.RENDER_SERVICE_URL || 'https://flodrama-scraper.onrender.com';
const RENDER_API_KEY = process.env.RENDER_API_KEY || 'rnd_DJfpQC9gEu4KgTRvX8iQzMXxrteP';
const SCRAPER_SCRIPT_PATH = path.join(__dirname, '../../.github/scripts/stealth/scraper-optimise.js');
const OUTPUT_DIR = path.join(__dirname, 'test-results');
const LOG_FILE = path.join(OUTPUT_DIR, 'test-log.txt');

// Sources √† tester (sous-ensemble des sources compl√®tes pour le test)
const TEST_SOURCES = [
  'tmdb-films',  // Source TMDB qui devrait toujours fonctionner
  'allocine-films',
  'allocine-series',
  'senscritique-films'
];

// Fonction pour logger dans le fichier et la console
function log(message) {
  const timestamp = new Date().toISOString();
  const logMessage = `[${timestamp}] ${message}`;
  console.log(logMessage);
  
  // S'assurer que le dossier de logs existe
  fs.ensureDirSync(path.dirname(LOG_FILE));
  
  // Ajouter au fichier de log
  fs.appendFileSync(LOG_FILE, logMessage + '\n');
}

// Fonction pour ex√©cuter le scraping local
async function runLocalScraping(source) {
  log(`üîç D√©marrage du scraping local pour la source: ${source}`);
  
  try {
    // Cr√©er un dossier temporaire pour les r√©sultats
    const tempOutputDir = path.join(OUTPUT_DIR, 'local', source);
    fs.ensureDirSync(tempOutputDir);
    
    // D√©finir les variables d'environnement pour le test
    process.env.USE_RELAY_SERVICE = 'false';
    process.env.DEBUG_MODE = 'true';
    process.env.OUTPUT_DIR = tempOutputDir;
    
    // Ex√©cuter le script de scraping
    const startTime = Date.now();
    const output = execSync(`node ${SCRAPER_SCRIPT_PATH} --sources=${source}`, { 
      encoding: 'utf8',
      env: process.env
    });
    const endTime = Date.now();
    const duration = (endTime - startTime) / 1000;
    
    // V√©rifier les r√©sultats
    const resultFiles = fs.readdirSync(tempOutputDir).filter(file => file.endsWith('.json'));
    const itemCount = resultFiles.length > 0 
      ? fs.readJsonSync(path.join(tempOutputDir, resultFiles[0])).length 
      : 0;
    
    log(`‚úÖ Scraping local termin√© en ${duration.toFixed(2)}s - ${itemCount} √©l√©ments r√©cup√©r√©s`);
    
    return {
      success: itemCount > 0,
      duration,
      itemCount,
      output
    };
  } catch (error) {
    log(`‚ùå Erreur lors du scraping local: ${error.message}`);
    return {
      success: false,
      duration: 0,
      itemCount: 0,
      error: error.message,
      output: error.stdout || ''
    };
  }
}

// Fonction pour ex√©cuter le scraping via le service relais Render
async function runRelayServiceScraping(source) {
  log(`üîÑ D√©marrage du scraping via le service relais pour la source: ${source}`);
  
  try {
    // Configuration par d√©faut si on ne trouve pas la source
    let sourceConfig = {
      urls: ['https://www.themoviedb.org/movie/popular'],
      selector: '.card',
      waitForSelector: '.page_wrapper',
      type: 'film'
    };
    
    // Essayer de r√©cup√©rer la configuration de la source depuis le script de scraping
    try {
      const scraperScript = fs.readFileSync(SCRAPER_SCRIPT_PATH, 'utf8');
      
      // Chercher la d√©finition compl√®te de la source
      const sourceBlockRegex = new RegExp(`{\\s*name:\\s*['"']${source}['"'][^}]*}`, 'gs');
      const sourceBlock = scraperScript.match(sourceBlockRegex);
      
      if (sourceBlock && sourceBlock.length > 0) {
        // Extraire les URLs
        const urlsMatch = sourceBlock[0].match(/urls:\s*\[([^\]]+)\]/s);
        if (urlsMatch && urlsMatch[1]) {
          sourceConfig.urls = urlsMatch[1]
            .split(',')
            .map(url => url.trim().replace(/['"`]/g, ''))
            .filter(url => url.length > 0);
        }
        
        // Extraire le s√©lecteur principal
        const selectorMatch = sourceBlock[0].match(/selector:\s*['"](.*?)['"]/);
        if (selectorMatch && selectorMatch[1]) {
          sourceConfig.selector = selectorMatch[1];
        }
        
        // Extraire le s√©lecteur d'attente
        const waitForSelectorMatch = sourceBlock[0].match(/waitForSelector:\s*['"](.*?)['"]/);
        if (waitForSelectorMatch && waitForSelectorMatch[1]) {
          sourceConfig.waitForSelector = waitForSelectorMatch[1];
        }
        
        // Extraire le type
        const typeMatch = sourceBlock[0].match(/type:\s*['"](.*?)['"]/);
        if (typeMatch && typeMatch[1]) {
          sourceConfig.type = typeMatch[1];
        }
      } else if (source === 'tmdb-films') {
        // Configuration sp√©ciale pour TMDB
        sourceConfig = {
          urls: ['https://api.themoviedb.org/3/movie/popular'],
          selector: '.movie-card',
          waitForSelector: '.movie-list',
          type: 'film'
        };
      } else {
        log(`‚ö†Ô∏è Configuration de la source ${source} non trouv√©e, utilisation des valeurs par d√©faut`);
      }
    } catch (error) {
      log(`‚ö†Ô∏è Erreur lors de l'extraction de la configuration: ${error.message}`);
    }
    
    // Utiliser la configuration extraite ou par d√©faut
    
    // Pr√©parer la requ√™te pour le service relais
    const payload = {
      source,
      type: sourceConfig.type,
      urls: sourceConfig.urls,
      selectors: {
        main: sourceConfig.selector,
        wait: sourceConfig.waitForSelector
      },
      minItems: 5
    };
    
    log(`üì° Configuration utilis√©e pour ${source}:`);
    log(`   URLs: ${payload.urls.join(', ')}`);
    log(`   S√©lecteur principal: ${payload.selectors.main}`);
    log(`   S√©lecteur d'attente: ${payload.selectors.wait}`);
    log(`   Type: ${payload.type}`);
    
    // Envoyer la requ√™te au service relais
    const startTime = Date.now();
    const response = await axios.post(`${RENDER_SERVICE_URL}/scrape`, payload, {
      headers: {
        'Authorization': `Bearer ${RENDER_API_KEY}`,
        'Content-Type': 'application/json'
      },
      timeout: 120000 // 2 minutes
    });
    const endTime = Date.now();
    const duration = (endTime - startTime) / 1000;
    
    // V√©rifier les r√©sultats
    const items = response.data && response.data.items ? response.data.items : [];
    log(`‚úÖ Scraping via service relais termin√© en ${duration.toFixed(2)}s - ${items.length} √©l√©ments r√©cup√©r√©s`);
    
    // Sauvegarder les r√©sultats
    const tempOutputDir = path.join(OUTPUT_DIR, 'relay', source);
    fs.ensureDirSync(tempOutputDir);
    fs.writeJsonSync(path.join(tempOutputDir, `${source}.json`), items, { spaces: 2 });
    
    return {
      success: items.length > 0,
      duration,
      itemCount: items.length,
      output: JSON.stringify(response.data, null, 2)
    };
  } catch (error) {
    log(`‚ùå Erreur lors du scraping via service relais: ${error.message}`);
    return {
      success: false,
      duration: 0,
      itemCount: 0,
      error: error.message,
      output: error.response ? JSON.stringify(error.response.data, null, 2) : ''
    };
  }
}

// Fonction principale
async function runScrapingTests() {
  log('üß™ D√©marrage des tests de scraping');
  log('================================================================================');
  
  // Cr√©er les dossiers de sortie
  fs.ensureDirSync(OUTPUT_DIR);
  fs.ensureDirSync(path.join(OUTPUT_DIR, 'local'));
  fs.ensureDirSync(path.join(OUTPUT_DIR, 'relay'));
  
  // Tableau pour stocker les r√©sultats
  const results = [];
  
  // Tester chaque source
  for (const source of TEST_SOURCES) {
    log(`\nüîç Test de la source: ${source}`);
    log('--------------------------------------------------------------------------------');
    
    // Test local
    const localResult = await runLocalScraping(source);
    
    // Test service relais
    const relayResult = await runRelayServiceScraping(source);
    
    // Comparer les r√©sultats
    const comparison = {
      source,
      local: {
        success: localResult.success,
        duration: localResult.duration,
        itemCount: localResult.itemCount
      },
      relay: {
        success: relayResult.success,
        duration: relayResult.duration,
        itemCount: relayResult.itemCount
      },
      comparison: {
        fasterMethod: localResult.duration < relayResult.duration ? 'local' : 'relay',
        speedDifference: Math.abs(localResult.duration - relayResult.duration).toFixed(2),
        moreItems: localResult.itemCount > relayResult.itemCount ? 'local' : 'relay',
        itemDifference: Math.abs(localResult.itemCount - relayResult.itemCount)
      }
    };
    
    results.push(comparison);
    
    log(`üìä Comparaison pour ${source}:`);
    log(`   Local: ${localResult.success ? '‚úÖ' : '‚ùå'} - ${localResult.duration.toFixed(2)}s - ${localResult.itemCount} √©l√©ments`);
    log(`   Relay: ${relayResult.success ? '‚úÖ' : '‚ùå'} - ${relayResult.duration.toFixed(2)}s - ${relayResult.itemCount} √©l√©ments`);
    log(`   Le plus rapide: ${comparison.comparison.fasterMethod} (diff√©rence: ${comparison.comparison.speedDifference}s)`);
    log(`   Le plus d'√©l√©ments: ${comparison.comparison.moreItems} (diff√©rence: ${comparison.comparison.itemDifference} √©l√©ments)`);
    
    log('--------------------------------------------------------------------------------');
  }
  
  // G√©n√©rer un rapport de synth√®se
  const successfulLocal = results.filter(r => r.local.success).length;
  const successfulRelay = results.filter(r => r.relay.success).length;
  const fasterLocal = results.filter(r => r.comparison.fasterMethod === 'local').length;
  const moreItemsLocal = results.filter(r => r.comparison.moreItems === 'local').length;
  
  log('\nüìã Rapport de synth√®se:');
  log('================================================================================');
  log(`Sources test√©es: ${TEST_SOURCES.length}`);
  log(`Succ√®s en local: ${successfulLocal}/${TEST_SOURCES.length} (${(successfulLocal/TEST_SOURCES.length*100).toFixed(0)}%)`);
  log(`Succ√®s via relais: ${successfulRelay}/${TEST_SOURCES.length} (${(successfulRelay/TEST_SOURCES.length*100).toFixed(0)}%)`);
  log(`Plus rapide en local: ${fasterLocal}/${TEST_SOURCES.length} (${(fasterLocal/TEST_SOURCES.length*100).toFixed(0)}%)`);
  log(`Plus d'√©l√©ments en local: ${moreItemsLocal}/${TEST_SOURCES.length} (${(moreItemsLocal/TEST_SOURCES.length*100).toFixed(0)}%)`);
  
  // Sauvegarder les r√©sultats complets
  fs.writeJsonSync(path.join(OUTPUT_DIR, 'test-results.json'), results, { spaces: 2 });
  log(`\n‚úÖ R√©sultats sauvegard√©s dans ${path.join(OUTPUT_DIR, 'test-results.json')}`);
  
  log('\n================================================================================');
  log('‚úÖ Tests de scraping termin√©s');
  log('================================================================================');
  
  return results;
}

// Ex√©cution de la fonction principale
runScrapingTests().catch(error => {
  log(`‚ùå Erreur fatale: ${error.message}`);
  process.exit(1);
});
