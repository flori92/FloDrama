/**
 * Script d'importation des donnÃ©es enrichies vers Cloudflare D1
 * 
 * Ce script prend les donnÃ©es enrichies et les importe dans la base de donnÃ©es
 * Cloudflare D1 pour Ãªtre utilisÃ©es par l'API et le frontend.
 * 
 * @author FloDrama Team
 * @version 1.0.0
 */

const fs = require('fs-extra');
const path = require('path');
const { execSync } = require('child_process');

// Configuration
const ENRICHED_DATA_DIR = path.join(__dirname, '../../.github/scripts/enrichment/enriched');
const TEMP_SQL_DIR = path.join(__dirname, './temp_sql');
const D1_DATABASE_NAME = 'flodrama-content';

// CrÃ©ation du dossier temporaire pour les fichiers SQL
fs.ensureDirSync(TEMP_SQL_DIR);

/**
 * Fonction principale d'importation
 */
async function importToD1() {
  console.log('ğŸ“¦ DÃ©marrage de l\'importation des donnÃ©es vers Cloudflare D1...');
  
  try {
    // VÃ©rification que les donnÃ©es enrichies existent
    if (!fs.existsSync(ENRICHED_DATA_DIR)) {
      console.error(`âŒ Le dossier des donnÃ©es enrichies n'existe pas: ${ENRICHED_DATA_DIR}`);
      process.exit(1);
    }
    
    // RÃ©cupÃ©ration des fichiers de donnÃ©es enrichies
    const files = await fs.readdir(ENRICHED_DATA_DIR);
    const jsonFiles = files.filter(file => file.endsWith('.json'));
    
    if (jsonFiles.length === 0) {
      console.warn('âš ï¸ Aucun fichier de donnÃ©es enrichies trouvÃ©.');
      process.exit(0);
    }
    
    console.log(`ğŸ“‚ ${jsonFiles.length} fichiers trouvÃ©s pour l'importation.`);
    
    // Statistiques d'importation
    let stats = {
      totalFiles: jsonFiles.length,
      totalItems: 0,
      importedItems: 0,
      failedItems: 0
    };
    
    // Traitement de chaque fichier
    for (const file of jsonFiles) {
      console.log(`ğŸ“„ Traitement du fichier: ${file}`);
      
      // Lecture du fichier
      const filePath = path.join(ENRICHED_DATA_DIR, file);
      const data = await fs.readJson(filePath);
      
      // VÃ©rification de la structure des donnÃ©es
      if (!Array.isArray(data.items)) {
        console.warn(`âš ï¸ Structure invalide dans ${file}, passage au fichier suivant.`);
        continue;
      }
      
      // Extraction du type de contenu Ã  partir du nom de fichier
      const contentType = file.replace('.json', '').toLowerCase();
      
      // GÃ©nÃ©ration du fichier SQL pour ce type de contenu
      const sqlFilePath = path.join(TEMP_SQL_DIR, `${contentType}.sql`);
      const sqlStatements = [];
      
      // Ajout de la transaction SQL
      sqlStatements.push('BEGIN TRANSACTION;');
      
      // Suppression des donnÃ©es existantes pour ce type
      sqlStatements.push(`DELETE FROM content WHERE type = '${contentType}';`);
      
      // PrÃ©paration des insertions
      for (const item of data.items) {
        stats.totalItems++;
        
        try {
          // PrÃ©paration des donnÃ©es pour l'insertion
          const insertData = prepareItemForInsert(item, contentType);
          
          // GÃ©nÃ©ration de la requÃªte SQL
          const insertSql = generateInsertSql(insertData);
          sqlStatements.push(insertSql);
          
          stats.importedItems++;
        } catch (error) {
          console.error(`âŒ Erreur lors de la prÃ©paration de l'Ã©lÃ©ment pour l'insertion:`, error.message);
          stats.failedItems++;
        }
      }
      
      // Finalisation de la transaction
      sqlStatements.push('COMMIT;');
      
      // Ã‰criture du fichier SQL
      await fs.writeFile(sqlFilePath, sqlStatements.join('\n'));
      
      console.log(`âœ… Fichier SQL gÃ©nÃ©rÃ©: ${sqlFilePath}`);
      
      // ExÃ©cution du fichier SQL avec wrangler
      try {
        console.log(`ğŸ”„ ExÃ©cution du fichier SQL pour ${contentType}...`);
        execSync(`wrangler d1 execute ${D1_DATABASE_NAME} --file=${sqlFilePath}`, { stdio: 'inherit' });
        console.log(`âœ… DonnÃ©es ${contentType} importÃ©es avec succÃ¨s dans D1.`);
      } catch (error) {
        console.error(`âŒ Erreur lors de l'exÃ©cution du fichier SQL pour ${contentType}:`, error.message);
      }
    }
    
    // GÃ©nÃ©ration des index et vues
    console.log('ğŸ”„ GÃ©nÃ©ration des index et vues...');
    await generateIndexesAndViews();
    
    // Rapport final
    console.log('\nğŸ“Š Rapport d\'importation:');
    console.log(`- Fichiers traitÃ©s: ${stats.totalFiles}`);
    console.log(`- Total d'Ã©lÃ©ments: ${stats.totalItems}`);
    console.log(`- Ã‰lÃ©ments importÃ©s: ${stats.importedItems}`);
    console.log(`- Ã‰checs d'importation: ${stats.failedItems}`);
    
    console.log('\nâœ… Importation terminÃ©e avec succÃ¨s!');
    
    // Nettoyage des fichiers temporaires
    await fs.remove(TEMP_SQL_DIR);
    
  } catch (error) {
    console.error('âŒ Erreur lors de l\'importation des donnÃ©es:', error);
    process.exit(1);
  }
}

/**
 * PrÃ©pare un Ã©lÃ©ment pour l'insertion en base de donnÃ©es
 * @param {Object} item - L'Ã©lÃ©ment Ã  prÃ©parer
 * @param {string} contentType - Le type de contenu
 * @returns {Object} - L'Ã©lÃ©ment prÃ©parÃ© pour l'insertion
 */
function prepareItemForInsert(item, contentType) {
  // CrÃ©ation d'un objet avec les champs nÃ©cessaires pour la base de donnÃ©es
  const insertData = {
    id: item.id || generateUniqueId(),
    title: item.title || '',
    original_title: item.original_title || item.title || '',
    type: contentType,
    source: item.source || '',
    url: item.url || '',
    poster_url: item.poster_path || item.poster_url || '',
    backdrop_url: item.backdrop_path || item.backdrop_url || '',
    description: item.overview || item.description || '',
    year: item.year || (item.release_date ? parseInt(item.release_date.substring(0, 4)) : null),
    rating: item.vote_average || item.rating || 0,
    genres: Array.isArray(item.genres) ? JSON.stringify(item.genres) : '[]',
    streaming_urls: Array.isArray(item.streaming_urls) ? JSON.stringify(item.streaming_urls) : '[]',
    trailer: item.trailer ? JSON.stringify(item.trailer) : null,
    cast: Array.isArray(item.cast) ? JSON.stringify(item.cast) : '[]',
    tmdb_id: item.tmdb_id || null,
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString(),
    is_enriched: item.is_enriched ? 1 : 0
  };
  
  return insertData;
}

/**
 * GÃ©nÃ¨re une requÃªte SQL INSERT pour un Ã©lÃ©ment
 * @param {Object} item - L'Ã©lÃ©ment prÃ©parÃ© pour l'insertion
 * @returns {string} - La requÃªte SQL INSERT
 */
function generateInsertSql(item) {
  const columns = Object.keys(item).join(', ');
  const values = Object.values(item).map(value => {
    if (value === null) return 'NULL';
    if (typeof value === 'string') return `'${value.replace(/'/g, "''")}'`;
    return value;
  }).join(', ');
  
  return `INSERT INTO content (${columns}) VALUES (${values});`;
}

/**
 * GÃ©nÃ¨re un identifiant unique
 * @returns {string} - Identifiant unique
 */
function generateUniqueId() {
  return `id_${Date.now()}_${Math.floor(Math.random() * 1000000)}`;
}

/**
 * GÃ©nÃ¨re les index et vues dans la base de donnÃ©es
 */
async function generateIndexesAndViews() {
  const sqlFilePath = path.join(TEMP_SQL_DIR, 'indexes_and_views.sql');
  
  // CrÃ©ation des index et vues
  const sql = `
-- Index pour amÃ©liorer les performances des requÃªtes
CREATE INDEX IF NOT EXISTS idx_content_type ON content(type);
CREATE INDEX IF NOT EXISTS idx_content_year ON content(year);
CREATE INDEX IF NOT EXISTS idx_content_rating ON content(rating);
CREATE INDEX IF NOT EXISTS idx_content_tmdb_id ON content(tmdb_id);

-- Vue pour les contenus les plus populaires
CREATE VIEW IF NOT EXISTS popular_content AS
SELECT * FROM content
WHERE rating > 7.0
ORDER BY rating DESC, year DESC
LIMIT 100;

-- Vue pour les contenus rÃ©cents
CREATE VIEW IF NOT EXISTS recent_content AS
SELECT * FROM content
WHERE year >= (SELECT strftime('%Y', 'now') - 2)
ORDER BY year DESC, rating DESC
LIMIT 100;

-- Vue pour les contenus par type
CREATE VIEW IF NOT EXISTS content_by_type AS
SELECT type, COUNT(*) as count
FROM content
GROUP BY type;
  `;
  
  // Ã‰criture du fichier SQL
  await fs.writeFile(sqlFilePath, sql);
  
  // ExÃ©cution du fichier SQL avec wrangler
  try {
    execSync(`wrangler d1 execute ${D1_DATABASE_NAME} --file=${sqlFilePath}`, { stdio: 'inherit' });
    console.log('âœ… Index et vues gÃ©nÃ©rÃ©s avec succÃ¨s.');
  } catch (error) {
    console.error('âŒ Erreur lors de la gÃ©nÃ©ration des index et vues:', error.message);
  }
}

// ExÃ©cution du script
importToD1().catch(error => {
  console.error('âŒ Erreur fatale:', error);
  process.exit(1);
});
